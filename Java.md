# Java

## 基础

### 静态方法为什么不能调用非静态成员

静态方法是**属于类**的，在**类加载的时候就会分配内存**，可以通过类名直接访问。而非静态成员**属于实例对象**，只有在**对象实例化之后才存在**，需要通过类的实例对象去访问。在类的非静态成员不存在的时候静态成员就已经存在了，此时调用在内存中还不存在的非静态成员，属于非法操作

### 重载和重写有什么区别

- **重载**：如果多个方法(比如 `StringBuilder` 的构造方法)有相同的名字、不同的参数， 便产生了重载
- **重写**：重写发生在运行期，是子类对父类的允许访问的方法的实现过程进行重新编写
  - 方法名、参数列表必须相同。如果方法的返回类型是 void 和基本数据类型，则返回值重写时不可修改；但是如果方法的返回值是引用类型，重写时是可以返回该引用类型的子类的。抛出的异常范围小于等于父类。访问修饰符范围大于等于父类。
  - 如果父类方法访问修饰符为 `private/final/static` 则子类就不能重写该方法，但是被 `static` 修饰的方法能够被再次声明。（重写形成的多态发生在运行期，静态方法在编译期形成，所以`static`方法不能被重写
  - 构造方法无法被重写

> 重载就是同样的一个方法能够**根据输入数据的不同，做出不同的处理**
>
> 重写就是当子类继承自父类的相同方法，**输入数据一样，但要做出有别于父类的响应时**，你就要覆盖父类方法

### 基本数据类型和占用内存大小

- 6 种数字类型：
  - 4 种整数型：`byte`（1字节）、`short`（2字节）、`int`（4字节）、`long`（8字节）
  - 2 种浮点型：`float`（4字节）、`double`（8字节）
- 1 种字符类型：`char`（**2字节**）
- 1 种布尔型：`boolean`（1位）

### 基本类型和包装类型的区别

- 成员变量包装类型不赋值就是 `null` ，而基本类型有默认值且不是 `null`。
- 包装类型可用于泛型，而基本类型不可以。
- 包装类型属于对象类型，几乎所有对象实例都存在于堆中。基本数据类型的局部变量存放在 Java 虚拟机栈中的局部变量表中，基本数据类型的成员变量（未被 `static` 修饰 ）存放在 Java 虚拟机的堆中。
- 相比于对象类型， 基本数据类型占用的空间非常小。

### 包装类型的缓存机制

Java 基本数据类型的包装类型的大部分都用到了缓存机制来提升性能

Byte`,`Short`,`Integer`,`Long 这 4 种包装类默认创建了数值 **[-128，127]** 的相应类型的缓存数据，`Character` 创建了数值在 **[0,127]** 范围的缓存数据，`Boolean` 直接返回 `True` or `False`。两种浮点数类型的包装类 `Float`,`Double` 并没有实现缓存机制。

如果超出对应范围仍然会去创建新的对象，缓存的范围区间的大小只是在性能和资源之间的权衡。

```java
// Integer 缓存源码：
public static Integer valueOf(int i) {
    if (i >= IntegerCache.low && i <= IntegerCache.high) {	
      return IntegerCache.cache[i + (-IntegerCache.low)];
    }
    return new Integer(i);
}
private static class IntegerCache {
    static final int low = -128;
    static final int high;
    static {
        // high value may be configured by property
        int h = 127;
    }
}
```

> **所有整型包装类对象之间值的比较，全部使用 equals 方法比较**

![img](https://img-blog.csdnimg.cn/20210422164544846.png)

### 自动装箱与拆箱

- **装箱**：将基本类型用它们对应的引用类型包装起来
- **拆箱**：将包装类型转换为基本数据类型

```Java
Integer i = 10;  // 装箱 等价于 Integer i = Integer.valueOf(10)
int n = i;   // 拆箱 等价于 int n = i.intValue()
```

### 面向对象和面向过程

- 面向过程**把解决问题的过程拆成一个个方法**，通过一个个方法的执行解决问题

- 面向对象会**先抽象出对象，然后用对象执行方法的方式解决问题**

  另外，面向对象开发的程序一般更易维护、易复用、易扩展

### 面向对象三大特征

#### 封装

把对象的**属性隐藏在对象内部**。**不允许外部对象直接访问对象的内部信息**。但是可以**提供一些可以被外界访问的方法来操作属性**。

#### 继承

不同类型的对象，相互之间经常有一定数量的**共同点**。继承是**使用已存在的类的定义作为基础建立新类**的技术，新类的定义可以增加新的数据或新的功能，也可以用父类的功能，但不能选择性地继承父类。通过使用继承，可以**快速地创建新的类，可以提高代码的重用，程序的可维护性，提高我们的开发效律**。

#### 多态

表示一个对象具有多种的状态，具体表现为父类的引用指向子类的实例

**多态的特点:**

- 对象类型和引用类型之间具有**继承（类）/实现（接口）**的关系
- 引用类型变量发出的方法调用的到底是哪个类中的方法，必须在**程序运行期间**才能确定
- 多态**不能调用**“只在子类存在但在父类不存在”的方法
- 如果子类重写了父类的方法，真正执行的是子类覆盖的方法，如果子类没有覆盖父类的方法，执行的是父类的方法

### 接口和抽象类的共同点和区别

**共同点** ：

- 都不能被实例化
- 都可以包含抽象方法
- 都可以有默认的实现方法（Java 8 可以用 `default` 关键字在接口中定义默认方法）

**区别** ：

- 接口主要用于对类的**行为**进行约束，你实现了某个接口就具有了对应的行为。抽象类主要用于代码复用，强调的是所属关系
- 一个类只能继承一个类，但是可以实现多个接口
- 接口中的**成员变量**只能是 `public static final` 类型的，不能被修改且必须有初始值，而抽象类的成员变量**默认 default**，可在子类中被重新定义，也可被重新赋值

### 内部类

- 成员内部类：作为成员对象的内部类。可以访问private及以上外部类的属性和方法。外部类想要访问内部类属性或方法时，必须要创建一个内部类对象，然后通过该对象访问内部类的属性或方法。外部类也可访问private修饰的内部类属性。
- 局部内部类：存在于方法中的内部类。访问权限类似局部变量。
- 匿名内部类：只能使用一次，没有类名。一般来说，匿名内部类用于继承其他类或是实现接口，并不需要增加额外的方法，只是对继承方法的实现或是重写
- 静态内部类：类似类的静态成员变量。

### 深拷贝、浅拷贝和引用拷贝

- **引用拷贝**：两个不同的引用指向同一个对象

- **浅拷贝**：浅拷贝会在堆上创建一个新的对象（区别于引用拷贝的一点），不过，如果原对象内部的属性是引用类型的话，浅拷贝会直接复制内部对象的引用地址，也就是说拷贝对象和原对象共用同一个内部对象

- **深拷贝**：深拷贝会完全复制整个对象，包括这个对象所包含的内部对象

  ![浅拷贝、深拷贝、引用拷贝示意图](https://guide-blog-images.oss-cn-shenzhen.aliyuncs.com/github/javaguide/java/basis/shallow&deep-copy.png)

### Object

#### == 和 equals() 的区别

**==**

- 对于基本数据类型来说，`==` 比较的是值
- 对于引用数据类型来说，`==` 比较的是对象的内存地址

> 因为 Java 只有值传递，所以，对于 == 来说，不管是比较基本数据类型，还是引用数据类型的变量，其本质比较的都是值，只是引用类型变量存的值是对象的地址。

**equals()**

不能用于判断基本数据类型的变量，只能用来判断两个对象是否相等

- **类没有重写 `equals()`方法** ：通过`equals()`比较该类的两个对象时，等价于通过“==”比较这两个对象，使用的默认是 `Object`类`equals()`方法。
- **类重写了 `equals()`方法** ：一般我们都重写 `equals()`方法来比较两个对象中的属性是否相等；若它们的属性相等，则返回 true(即，认为这两个对象相等)。

#### hashCode()

`hashCode()` 的作用是获取哈希码（`int` 整数），也称为散列码。这个哈希码的作用是确定该对象在哈希表中的索引位置。

`hashCode()` 和 `equals()`都是用于比较两个对象是否相等。在一些容器中，比如`HashSet`或`HashMap`，比较对象相等会先采用 hashCode() 方法比较散列值，散列值不同可以直接说明两个对象不相等；散列值相同的两个对象也不一定完全相等，此时再用 equals() 方法判断是否真的相等。也就是说 `hashCode` 帮助我们大大缩小了查找成本。

#### 为什么重写 equals() 时必须重写 hashCode() 方法

如果 `equals` 方法判断两个对象是相等的，那这两个对象的 `hashCode` 值也要相等。

如果重写 `equals()` 时没有重写 `hashCode()` 方法的话就可能会导致 `equals` 方法判断是相等的两个对象，`hashCode` 值却不相等。

### String

#### String、StringBuffer、StringBuilder 的区别

**可变性**

`String` 是不可变的，`StringBuilder` 与 `StringBuffer` 可变

**线程安全性**

`String` 中的对象是不可变的，也就可以理解为常量，线程安全。`StringBuffer` 对方法加了同步锁或者对调用的方法加了同步锁，所以是线程安全的。`StringBuilder` 并没有对方法进行加同步锁，所以是非线程安全的。

**性能**

每次对 `String` 类型进行改变的时候，都会生成一个新的 `String` 对象，然后将指针指向新的 `String` 对象。`StringBuffer` 每次都会对 `StringBuffer` 对象本身进行操作，而不是生成新的对象并改变对象引用。相同情况下使用 `StringBuilder` 相比使用 `StringBuffer` 仅能获得 10%~15% 左右的性能提升，但却要冒多线程不安全的风险。

#### String 为什么是不可变的

- 保存字符串的数组被 `final` 修饰且为**私有**的，并且`String` 类没有提供/暴露修改这个字符串的方法
- `String` 类被 `final` 修饰导致其不能被继承，进而避免了子类破坏 `String` 不可变

#### 字符串拼接用 “+” 还是 StringBuilder.append()

字符串对象通过“+”的字符串拼接方式，实际上是通过 `StringBuilder` 调用 `append()` 方法实现的，拼接完成之后调用 `toString()` 得到一个 `String` 对象 。不过，在**循环内**使用“+”进行字符串的拼接的话，存在比较明显的缺陷：**编译器不会创建单个 `StringBuilder`** 以复用，会导致创建过多的 `StringBuilder` 对象集合。如果直接使用 `StringBuilder` 对象进行字符串拼接的话，就不会存在这个问题了

#### 字符串常量池

**字符串常量池** 是 JVM 为了提升性能和减少内存消耗针对字符串（String 类）专门开辟的一块区域，主要目的是为了避免字符串的重复创建

```Java
// 在堆中创建字符串对象”ab“
// 将字符串对象”ab“的引用保存在字符串常量池中
String aa = "ab";
// 直接返回字符串常量池中字符串对象”ab“的引用
String bb = "ab";
System.out.println(aa==bb);// true
```

####  intern 方法有什么作用

`String.intern()` 是一个 native（本地）方法，其作用是**将指定的字符串对象的引用保存在字符串常量池**中，可以简单分为两种情况：

- 如果字符串常量池中保存了对应的字符串对象的引用，就直接返回该引用。
- 如果字符串常量池中没有保存了对应的字符串对象的引用，那就在常量池中创建一个指向该字符串对象的引用并返回

### 异常

#### Exception 和 Error 有什么区别

- **Exception**：程序本身可以处理的异常，可以通过 `catch` 来进行捕获
- **Error**：属于程序无法处理的错误，发生Error时，Java 虚拟机（JVM）一般会选择线程终止

#### Checked Exception 和 Unchecked Exception 有什么区别

- **Checked Exception**：受检查异常 （编译时异常），Java 代码在编译过程中，如果受检查异常没有被 `catch`或者`throws` 关键字处理的话，就没办法通过编译
- **Unchecked Exception**：非受检查异常 （运行时异常），Java 代码在编译过程中 ，我们即使不处理不受检查异常也可以正常通过编译，常见的有：
  - `NullPointerException`(空指针错误)
  - `ArrayIndexOutOfBoundsException`（数组越界错误）
  - `ClassCastException`（类型转换错误）
  - ......

#### finally中的代码一定会执行吗

首先，无论是否捕获或处理异常，`finally` 块里的语句都会被执行。但是，在某些情况下，finally 中的代码不会被执行。比如说 finally 之前虚拟机被终止运行的话，finally 中的代码就不会被执行。（程序所在的线程死亡、关闭 CPU）

### 泛型

使用泛型参数，可以增强代码的可读性以及稳定性。编译器可以对泛型参数进行检测，并且通过泛型参数可以指定传入的对象类型

**泛型通配符**

- **无限通配符 <?>**：List<?> 的意思是这个集合是一个可以持有任意类型的集合，因为你不知道集合是哪种类型，所以你**只能够对集合进行读操作**。并且你只能把读取到的元素当成 Object 实例来对待
- **上界通配符<? extends>**：List<? extends A> 代表的是一个可以持有 A 及其子类的实例的List集合。仍然只可以读取元素，不能插入A及其子类元素
- **下界通配符<? super>**：List<? super A> 的意思是List集合 list,它可以持有 A 及其父类的实例。此时可以读取元素，也能插入A及其子类元素

**泛型擦除**：Java在**编译期间**，所有的泛型信息都会被擦掉，在生成的字节码中是不包含泛型中的类型信息的

### 反射

反射是框架的灵魂，它赋予了我们**在运行时分析类以及执行类中方法的能力**。通过反射你可以**获取任意一个类的所有属性和方法，你还可以调用这些方法和属性**。

框架中大量使用了动态代理，**动态代理的实现也依赖反射**

**优缺点**：可以让咱们的代码更加灵活、为各种框架提供开箱即用的功能提供了便利。在运行时有了分析操作类的能力，这同样也增加了安全问题。比如可以无视泛型参数的安全检查（泛型参数的安全检查发生在编译时）。

#### 为什么使用反射

通过反射机制动态的加载指定的类，然后再实例化对象

#### 对反射的理解(作用、原理、应用场景）

**反射的作用**

- 在运行时（动态编译）获知任意一个对象所属的类。
- 在运行时构造任意一个类的对象。
- 在运行时获知任意一个类所具有的成员变量和方法。
- 在运行时调用任意一个对象的方法和属性

**反射的原理**

JVM 会将我们的代码编译成一个 `.class` 字节码文件，然后被类加载器（ClassLoader）加载进 JVM 的内存中，同时会创建这个类的 `Class` 对象存到堆中（注意这个不是 new 出来的对象，而是类的类型对象）。在加载完一个类后，堆内存的方法区就产生了一个 `Class` 对象，并且包含了这个类的完整结构信息。

通过调用 `getClass()` 方法后，我们就获得了这个类对应的 `Class` 对象，看到了这个类的结构。

#### 动态代理

动态代理它是代理模式的一种，所谓代理模式就是，**使用代理对象来代替对真实对象的访问，这样就可以在不修改原目标对象的前提下，提供额外的功能操作，扩展目标对象的功能**。

首先讲静态代理

静态代理就是，对于你想要增强的委托类，我们需要新建一个代理类，这两个类**实现一个同样的接口**，然后将**委托类注入进代理类**中，在代理类的方法中调用委托类中的对应方法。这样，我们就可以通过代理类**屏蔽对目标对象的访问**，并且可以在目标方法执行前后做一些自己想做的事情。

静态代理的弊端很明显，**一个委托类对应一个代理类，多个委托类就需要新建多个代理类**，我们能不能将代理类做成一个通用的呢？

动态代理就是解决这样的问题

同样的，JDK 动态代理需要委托类实现一个接口，不过代理类就不需要也实现同样的接口了，但是，JDK 动态代理机制中添加了一个新的角色，那就是处理类。具体来说，我们需要新建一个处理类，然后**将委托类注入处理类，另外，这个处理类需要实现 `InvocationHandler` 接口，并重写其 `invoke` 方法，在 `invoke` 方法中可以利用反射机制调用委托类的方法，并可以在其前后添加一些额外的处理逻辑**

JDK 动态代理有一个最致命的问题是它**只能代理实现了某个接口的实现类，并且代理类也只能代理接口中实现的方法**，要是实现类中有自己私有的方法，而接口中没有的话，该方法就不能进行代理调用。

为了解决这个问题，我们可以用 CGLIB 动态代理机制。动态代理就是通过字节码技术生成一个子类，并在**子类中拦截父类方法的调用（这也就是为什么说 CGLIB 是基于继承的了），织入额外的业务逻辑**。关键词就是拦截。

静态代理在编译时就将接口、实现类、代理类这些都变成了一个个实际的 `.class` 字节码文件。而动态代理是在运行时动态生成类字节码，并加载到 JVM 中的。

## I/O

- `InputStream`/`Reader`: 所有的输入流的基类，前者是字节输入流，后者是字符输入流
- `OutputStream`/`Writer`: 所有输出流的基类，前者是字节输出流，后者是字符输出流

#### I/O 流为什么要分为字节流和字符流呢

如果我们不知道编码类型的话，使用字节流的过程中很容易出现乱码问题

#### BIO、NIO 和 AIO 的区别

![img](https://images.xiaozhuanlan.com/photo/2020/33b193457c928ae02217480f994814b6.png)

**BIO(Blocking IO)**

**BIO 属于同步阻塞 IO 模型** 。同步阻塞 IO 模型中，应用程序发起 read 调用后，会一直阻塞，直到内核把数据拷贝到用户空间。

![同步阻塞 IO 模型](https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/6a9e704af49b4380bb686f0c96d33b81~tplv-k3u1fbpfcp-watermark.image)

**NIO(Non-blocking/New I/O)**

Java 中的 NIO 可以看作是 **I/O 多路复用模型**。

首先看同步非阻塞 IO 模型。同步非阻塞 IO 模型中，**应用程序会一直发起 read 调用，等待数据从内核空间拷贝到用户空间的这段时间里，线程依然是阻塞的，直到在内核把数据拷贝到用户空间**。相比于同步阻塞 IO 模型，同步非阻塞 IO 模型确实有了很大改进。通过**轮询**操作，避免了一直阻塞。但是，这种 IO 模型同样存在问题：**应用程序不断进行 I/O 系统调用轮询数据是否已经准备好的过程是十分消耗 CPU 资源的**。

![图源：《深入拆解Tomcat & Jetty》](https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/bb174e22dbe04bb79fe3fc126aed0c61~tplv-k3u1fbpfcp-watermark.image)

I/O 多路复用模型。IO 多路复用模型中，线程首先发起 select 调用，询问内核数据是否准备就绪，等内核把数据准备好了，用户线程再发起 read 调用。read 调用的过程（数据从内核空间 -> 用户空间）还是阻塞的。

![img](https://p6-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/88ff862764024c3b8567367df11df6ab~tplv-k3u1fbpfcp-watermark.image)

Java 中的 NIO ，有一个非常重要的**选择器 ( Selector )** 的概念，也可以被称为 **多路复用器**。通过它，只需要一个线程便可以管理多个客户端连接。当客户端数据到了之后，才会为其服务。

![img](https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/0f483f2437ce4ecdb180134270a00144~tplv-k3u1fbpfcp-watermark.image)

**AIO(Asynchronous I/O)**

异步 IO 是基于事件和回调机制实现的，也就是应用操作之后会直接返回，不会堵塞在那里，当后台处理完成，操作系统会通知相应的线程进行后续的操作。

![img](https://p1-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/3077e72a1af049559e81d18205b56fd7~tplv-k3u1fbpfcp-watermark.image)



#### select、poll、epoll 的区别

select、poll 只会通知用户进程有 FD 准备就绪，但不确定具体是哪个 FD，需要用户进程逐个遍历 FD 来确认。epoll 则会在通知用户进程 FD 准备就绪的同时，把已就绪的 FD 写入用户空间

- **select**：
  - 需要将整个 fd_set 从用户空间拷贝到内核空间，select 结束还要再次拷贝回用户空间
  - select 无法得知具体是哪个 fd 准备就绪，需要遍历整个 fd_set
  - fd_set 的数量不能超过 1024
  
- **poll**：对 select 做了简单改进，性能提升不明显，只有使用链表解决监听的 fd 数量上限问题，但是监听的 fd 越多，遍历的消耗越大

- **epoll**：
  
  - 用户态和内核态的转换只发生在传递批量 fd 和 调用 recvfrom 的时候，在 fd 准备就绪的时候，内核态会将 fd 添加到共享内存，即内核态和用户态都能访问到的空间
  
  - 使用红黑树没有 fd 数量的限制，并且增删改查的性能都较好
  
  - epoll 的就绪队列中可以知道具体是哪个 fd 准备就绪
  
    > - LT 模式下，只要这个 fd 还有数据可读，每次 epoll_wait 都会返回它的事件，提醒用户程序去操作；
    >
    >   对用户较为友好，但是系统消耗较多，执行效率较高
    >
    > - ET 模式下，它只会提示一次，直到下次再有数据流入之前都不会再提示了，无论 fd 中是否还有数据可读。所以在 ET 模式下，read 一个 fd 的时候一定要把它的 buffer 读完，或者遇到 EAGIN 错误。消耗的系统资源较少，执行效率较低，编写的代码也更复杂一些

## 集合

### List

#### ArrayList 和 Vector 的区别

- `ArrayList` 是 `List` 的主要实现类，底层使用 `Object[]`存储，适用于频繁的查找工作，线程不安全 ；
- `Vector` 是 `List` 的古老实现类，底层使用`Object[]` 存储，**线程安全**的。

#### ArrayList 与 LinkedList 区别

- **是否保证线程安全：** `ArrayList` 和 `LinkedList` 都是不同步的，也就是不保证线程安全；
- **底层数据结构：** `ArrayList` 底层使用的是 **`Object` 数组**；`LinkedList` 底层使用的是 **双向链表** 数据结构
- **是否支持快速随机访问：** `LinkedList` 不支持高效的随机元素访问，而 `ArrayList` 支持。快速随机访问就是通过元素的序号快速获取元素对象(对应于`get(int index)`方法)
- **插入和删除**：`ArrayList` 采用数组存储，所以插入和删除元素的时间复杂度受元素位置的影响。`LinkedList` 采用链表存储，所以，如果是**在头尾插入或者删除**元素不受元素位置的影响，如果是要在指定位置 `i` 插入和删除元素的话， 时间复杂度为 O(n) 

#### ArrayList 的扩容机制

以无参数构造方法创建 `ArrayList` 时，实际上初始化赋值的是一个空数组。**当对数组进行添加元素操作时，才真正分配容量**。即向数组中添加第一个元素时，数组容量扩为 10。直到添加第 11 个元素，进入 grow 方法进行扩容。**ArrayList 每次扩容之后容量都会变为原来的 1.5 倍左右（oldCapacity 为偶数就是 1.5 倍，否则是 1.5 倍左右）**

### Set

#### 比较 HashSet、LinkedHashSet 和 TreeSet 三者的异同

- `HashSet`、`LinkedHashSet` 和 `TreeSet` 都是 `Set` 接口的实现类，都能保证元素唯一，并且都不是线程安全的。
- `HashSet`、`LinkedHashSet` 和 `TreeSet` 的主要区别在于**底层数据结构**不同。`HashSet` 的底层数据结构是哈希表（基于 `HashMap` 实现）。`LinkedHashSet` 的底层数据结构是链表和哈希表，元素的插入和取出顺序满足 FIFO。`TreeSet` 底层数据结构是红黑树，元素是有序的，排序的方式有自然排序和定制排序。
- 底层数据结构不同又导致这三者的**应用场景**不同。`HashSet` 用于不需要保证元素插入和取出顺序的场景，`LinkedHashSet` 用于保证元素的插入和取出顺序满足 FIFO 的场景，`TreeSet` 用于支持对元素自定义排序规则的场景。

### Map

#### HashMap 和 Hashtable 的区别

- **线程是否安全：**`HashMap` 是非线程安全的，`Hashtable` 是线程安全的,因为 `Hashtable` 内部的方法基本都经过`synchronized` 修饰。（如果要保证线程安全可以使用 `ConcurrentHashMap` ）
- **效率：** 因为线程安全的问题，`HashMap` 要比 `Hashtable` 效率高一点。另外，`Hashtable` 基本被淘汰，不要在代码中使用它
- **初始容量大小和每次扩充容量大小的不同**
- **底层数据结构**
- **对 Null key 和 Null value 的支持**

#### HashMap 和 HashSet 区别

`HashSet` 底层就是基于 `HashMap` 实现的。（`HashSet` 的源码非常非常少，因为除了 `clone()`、`writeObject()`、`readObject()`是 `HashSet` 自己不得不实现之外，其他方法都是直接调用 `HashMap` 中的方法

#### HashMap 底层实现

**JDK1.8 之前**

 `HashMap` 底层是 **数组和链表** 结合在一起使用也就是 **链表散列**。HashMap 通过 key 的 `hashcode` 经过扰动函数处理过后得到 hash 值，然后通过 `(n - 1) & hash` 判断当前元素存放的位置（这里的 n 指的是数组的长度），如果当前位置存在元素的话，就判断该元素与要存入的元素的 hash 值以及 key 是否相同，如果相同的话，直接覆盖，不相同就通过拉链法解决冲突。

**JDK1.8 之后**

JDK1.8 之后在解决哈希冲突时有了较大的变化，当链表长度大于阈值（默认为 8）（将链表转换成红黑树前会判断，如果当前数组的长度小于 64，那么会选择先进行数组扩容，而不是转换为红黑树）时，将链表转化为红黑树，以减少搜索时间

> 红黑树是一颗二叉平衡查找树，但是不严格遵守平衡树的条件。红黑树的查找效率没有AVL高（红黑树路径长度不会超过2log(n+1)），但是修改的效率更高，综合下来效率也更高。红黑树的特点如下
>
> - 跟节点和叶子结点均为黑色结点
> - 相邻的两个结点不能都为红色结点
> - 任意结点到叶子结点的路径包含相同数量的黑色结点

#### HashMap 扩容机制

**JDK 1.7**



**JDK 1.8**

- **空参数的构造函数**：实例化的HashMap默认内部数组是null，即没有实例化。第一次调用put方法时，则会开始第一次初始化扩容，长度为16。
- **有参构造函数**：用于指定容量。会根据指定的正整数找到**不小于指定容量的2的幂数**，将这个数设置赋值给**阈值**（threshold）。第一次调用put方法时，会将阈值赋值给容量，然后让 阈值= 容量 × 负载因子 。（因此并不是我们手动指定了容量就一定不会触发扩容，超过阈值后一样会扩容！！）
- 如果不是第一次扩容，则容量变为原来的2倍，阈值也变为原来的2倍。*（容量和阈值都变为原来的2倍时，负载因子还是不变）*

实例化的HashMap默认内部数组是null，即没有实例化。第一次调用put方法时，则会开始第一次初始化扩容，长度为16。不是首次调用时，则会先存数据，再判断是否需要扩容。

一般情况下，**当元素数量超过阈值时**便会触发扩容。每次扩容的容量都是之前容量的2倍，阈值也变为原来的2倍。

#### HashMap 源码中，计算 hash 值为什么有一个 高 16 位 和 低 16 位异或的过程

为了保证更好的散列性。主要原因是保留高16位与低16位的特性，增大散列程度，和位运算有关。其次可以避免 hashmap 扩容以后重新计算 hash 值。

#### HashMap 的长度为什么是 2 的幂次方

hash 函数设计好的话 hash 值就会均匀分散，不易碰撞，但是 hash 值得范围太大的话内存放不下。所以 hash 值不能直接拿来用，用之前还要先做对数组的长度取模运算。**取余(%)操作中如果除数是 2 的幂次则等价于与其除数减一的与(&)操作**。并且 **采用二进制位操作 &，相对于%能够提高运算效率**

#### ConcurrentHashMap 和 Hashtable 的区别

- **底层数据结构**：JDK1.7 的 `ConcurrentHashMap` 底层采用 **分段的数组+链表** 实现，JDK1.8 采用的数据结构跟 `HashMap1.8` 的结构一样，数组+链表/红黑二叉树。`Hashtable` 和 JDK1.8 之前的 `HashMap` 的底层数据结构类似都是采用 **数组+链表** 的形式

- **实现线程安全的方式**：

  - **ConcurrentHashMap**

    - 在 JDK1.7 的时候，`ConcurrentHashMap` 对整个桶数组进行了分割分段(`Segment`，分段锁)，每一把锁只锁容器其中一部分数据，多线程访问容器里不同数据段的数据，就不会存在锁竞争，提高并发访问率。

    ![Java 7 ConcurrentHashMap 存储结构](https://guide-blog-images.oss-cn-shenzhen.aliyuncs.com/github/javaguide/java/collection/java7_concurrenthashmap.png)

    - 到了 JDK1.8 的时候，`ConcurrentHashMap` 已经摒弃了 `Segment` 的概念，而是直接用 `Node` 数组 + 链表 + 红黑树的数据结构来实现，并发控制使用 `synchronized` 和 CAS 来操作。（JDK1.6 以后 `synchronized` 锁做了很多优化） 整个看起来就像是优化过且线程安全的 `HashMap`

      Java 8 中，锁粒度更细，`synchronized` 只锁定当前链表或红黑二叉树的首节点，这样只要 hash 不冲突，就不会产生并发，就不会影响其他 Node 的读写，效率大幅提升

      ![Java8 ConcurrentHashMap 存储结构（图片来自 javadoop）](https://guide-blog-images.oss-cn-shenzhen.aliyuncs.com/github/javaguide/java/collection/java8_concurrenthashmap.png)
  
  - **HashTable**
  
    使用 `synchronized` 来保证线程安全，效率非常低下。当一个线程访问同步方法时，其他线程也访问同步方法，可能会进入阻塞或轮询状态

## 并发

### 进程和线程

#### 进程和线程的区别

**线程是进程划分成的更小的运行单位**。线程和进程最大的不同在于基本上各进程是独立的，而各线程则不一定，因为同一进程中的线程极有可能会相互影响、共享资源。线程执行开销小，但不利于资源的管理和保护；而进程正相反。

#### 线程的生命周期和状态

- NEW: 初始状态，线程被创建出来但没有被调用 `start()` 

- RUNNABLE: 运行状态，线程被调用了 `start()`等待运行的状态

- BLOCKED ：阻塞状态，需要等待锁释放

- WAITING：等待状态，表示该线程需要等待其他线程做出一些特定动作（通知或中断）

  TIME_WAITING：超时等待状态，可以在指定的时间后自行返回而不是像 WAITING 那样一直等待

- TERMINATED：终止状态，表示该线程已经运行完毕

#### 上下文切换

线程在执行过程中会有自己的运行条件和状态（也称上下文），比程序计数器，栈信息等。当发生线程切换的时候，就需要保存当前线程的上下文，留待线程下次占用 CPU 的时候恢复线程。并加载下一个将要占用 CPU 的线程上下文。这就是所谓的 **上下文切换**

#### sleep() 方法和 wait() 方法对比

- `wait()` 方法释放了锁，`sleep()` 方法没有释放锁
- `wait()` 通常被用于线程间交互/通信，`sleep()`通常被用于暂停执行。
- `wait()` 方法被调用后，线程不会自动苏醒，需要别的线程调用同一个对象上的 `notify()`或者 `notifyAll()` 方法。`sleep()`方法执行完成后，线程会自动苏醒，或者也可以使用 `wait(long timeout)` 超时后线程会自动苏醒
- `sleep()` 是 `Thread` 类的静态本地方法，`wait()` 则是 `Object` 类的本地方法

#### 为什么 wait() 方法不定义在 Thread 中

`wait()` 是让获得对象锁的线程实现等待，并且自动释放当前线程占有的对象锁。每个对象（`Object`）都拥有对象锁，既然要释放当前线程占有的对象锁并让其进入 WAITING 状态，自然是要操作对应的对象（`Object`）而非当前的线程（`Thread`）

#### 为什么 sleep() 方法定义在 `Thread` 中

`sleep()` 是让当前线程暂停执行，不涉及到对象类，也不需要获得对象锁

#### 可以直接调用 Thread 类的 run 方法吗

调用 `start()` 方法方可启动线程并使线程进入就绪状态，直接执行 `run()` 方法的话不会以多线程的方式执行，会变成主线程下的一个普通方法

### 乐观锁和悲观锁

- **悲观锁**：总是假设最坏的情况，**认为共享资源每次被访问的时候就会出现问题(比如共享数据被修改)，所以每次在获取资源操作的时候都会上锁**，这样其他线程想拿到这个资源就会阻塞直到锁被上一个持有者释放。像 Java 中`synchronized`和`ReentrantLock`等独占锁就是悲观锁思想的实现
- **乐观锁**：乐观锁总是假设最好的情况，**认为共享资源每次被访问的时候不会出现问题**，线程可以不停地执行，**无需加锁也无需等待，只是在提交修改的时候去验证对应的资源（也就是数据）是否被其它线程修改了**。 Java 中`java.util.concurrent.atomic`包下面的原子变量类就是使用了乐观锁的一种实现方式 **CAS** 实现的

#### CAS算法

CAS 的全称是 **Compare And Swap（比较与交换）**。思想很简单，就是用一个预期值和要更新的变量值进行比较，两值相等才会进行更新。CAS 是一个原子操作，底层依赖于一条 CPU 的原子指令。

CAS 涉及到三个操作数：

CAS 涉及到三个操作数：

- **V** ：要更新的变量值(Var)
- **E** ：预期值(Expected)
- **N** ：拟写入的新值(New)

当且仅当 V 的值等于 E 时，CAS 通过原子方式用新值 N 来更新 V 的值。如果不等，说明已经有其它线程更新了V，则当前线程放弃更新。

当多个线程同时使用 CAS 操作一个变量时，只有一个会胜出，并成功更新，其余均会失败，但失败的线程并不会被挂起，仅是被告知失败，并且允许再次尝试，当然也允许失败的线程放弃操作

#### 乐观锁的问题

- **ABA问题**：如果一个变量 V 初次读取的时候是 A 值，并且在准备赋值的时候检查到它仍然是 A 值，那我们就能说明它的值没有被其他线程修改过了吗？很明显是不能的，因为在这段时间它的值可能被改为其他值，然后又改回 A，那 CAS 操作就会误认为它从来没有被修改过。这个问题被称为 CAS 操作的 **"ABA"问题**。ABA 问题的解决思路是在变量前面追加上**版本号或者时间戳**。
- **循环开销时间大**：CAS 经常会用到自旋操作来进行重试，也就是不成功就一直循环执行直到成功。如果长时间不成功，会给 CPU 带来非常大的执行开销

### volatile

#### 如何保证变量的可见性

如果我们将变量声明为 **`volatile`** ，这就指示 JVM，这个变量是共享且不稳定的，**每次使用它都到主存中进行读取**

#### 如何禁止指令重排序

如果我们将变量声明为 **`volatile`** ，在对这个变量进行读写操作的时候，汇编指令带有 lock 前缀，相当于一个内存屏障，通过插入特定的 **内存屏障** 的方式来禁止指令重排序。

#### 可以保证原子性吗

不能，可以利用 `synchronized` 、`Lock`或者`AtomicInteger`解决

### synchronized

`synchronized` 是 Java 中的一个关键字，翻译成中文是同步的意思，**主要解决的是多个线程之间访问资源的同步性**，可以保证被它修饰的方法或者代码块在任意时刻只能有一个线程执行

#### synchronized原理

Java **对象底层都关联一个的 monitor**，使用 synchronized 时 JVM 会根据使用环境找到对象的monitor，根据 **monitor 的状态进行加解锁的判断**。如果成功加锁就成为该 monitor 的唯一持有者，

monitor 在被释放前不能再被其他线程获取。**synchronized 在 JVM 编译后会产生 monitorenter 和 monitorexit 这两个字节码指令，获取和释放monitor**。执行 monitorenter 指令时，首先尝试获取对象锁。如果这个对象没有被锁定，或当前线程已经持有锁，就把锁的**计数器**加 1，执行 monitorexit 指令时会将锁计数器减 1。一旦计数器为 0 锁随即就被释放。

#### synchronized 锁优化 

![img](https://ask.qcloudimg.com/http-save/yehe-4728726/7e59c95f680100fd939972cca38aa2ef.jpeg?imageView2/2/w/1620)

#### synchronized 和 volatile 有什么区别

`synchronized` 关键字和 `volatile` 关键字是两个互补的存在，而不是对立的存在！

- `volatile` 关键字是线程同步的轻量级实现，所以 `volatile`性能肯定比`synchronized`关键字要好 。但是 `volatile` 关键字只能用于变量而 `synchronized` 关键字可以修饰方法以及代码块 。
- `volatile` 关键字能保证数据的可见性，但不能保证数据的原子性。`synchronized` 关键字两者都能保证。
- `volatile`关键字主要用于解决变量在多个线程之间的可见性，而 `synchronized` 关键字解决的是多个线程之间访问资源的同步性

#### synchronized 和 ReentrantLock 有什么区别

两者都是**可重入锁**，可重入锁是指一个线程获得了某个对象的锁，此时这个对象锁还没有释放，当其再次想要获取这个对象的锁的时候还是可以获取的，如果是不可重入锁的话，就会造成死锁。

**ReentrantLock 比 synchronized 增加了一些高级功能**

- **等待可中断** : `ReentrantLock`提供了一种能够中断等待锁的线程的机制，通过 `lock.lockInterruptibly()` 来实现这个机制。也就是说正在等待的线程可以选择放弃等待，改为处理其他事情
- **可实现公平锁** : `ReentrantLock`可以指定是公平锁还是非公平锁。而**`synchronized`只能是非公平锁。所谓的公平锁就是先等待的线程先获得锁**。`ReentrantLock`默认情况是非公平的，可以通过 `ReentrantLock`类的`ReentrantLock(boolean fair)`构造方法来制定是否是公平的

### ThreadLocal

通常情况下，我们创建的变量是可以被任何一个线程访问并修改的。**如果想实现每一个线程都有自己的专属本地变量该如何解决呢？**

JDK 中自带的`ThreadLocal`类正是为了解决这样的问题。 **`ThreadLocal`类主要解决的就是让每个线程绑定自己的值**

如果你创建了一个`ThreadLocal`变量，那么访问这个变量的每个线程都会有这个变量的本地副本，这也是`ThreadLocal`变量名的由来。他们可以使用 `get()` 和 `set()` 方法来获取默认值或将其值更改为当前线程所存的副本的值，从而避免了线程安全问题

#### ThreadLocal 原理

每个`Thread`中都具备一个`ThreadLocalMap`，**最终的变量是放在了当前线程的 `ThreadLocalMap` 中，并不是存在 `ThreadLocal` 上，`ThreadLocal` 可以理解为只是`ThreadLocalMap`的封装，传递了变量值**。而`ThreadLocalMap`可以存储以`ThreadLocal`为 key ，Object 对象为 value 的键值对。

#### ThreadLocal 内存泄露问题

`ThreadLocalMap` 中使用的 key 为 `ThreadLocal` 的弱引用，而 value 是强引用。所以，如果 `ThreadLocal` 没有被外部强引用的情况下，在垃圾回收的时候，key 会被清理掉，而 value 不会被清理掉。这样一来，`ThreadLocalMap` 中就会出现 key 为 null 的 Entry。假如我们不做任何措施的话，value 永远无法被 GC 回收，这个时候就可能会产生内存泄露

**解决方法**：在调用 `set()`、`get()`、`remove()` 方法的时候，会清理掉 key 为 null 的记录。使用完 `ThreadLocal`方法后 最好手动调用`remove()`方法

### Atomic 原子类

#### 基本类型

**使用原子的方式更新基本类型**

- `AtomicInteger`：整型原子类
- `AtomicLong`：长整型原子类
- `AtomicBoolean` ：布尔型原子类

**数组类型**

使用原子的方式更新数组里的某个元素

- `AtomicIntegerArray`：整型数组原子类
- `AtomicLongArray`：长整型数组原子类
- `AtomicReferenceArray` ：引用类型数组原子类

**引用类型**

- `AtomicReference`：引用类型原子类
- `AtomicMarkableReference`：原子更新带有标记的引用类型。该类将 boolean 标记与引用关联起来
- `AtomicStampedReference` ：原子更新带有版本号的引用类型。该类将整数值与引用关联起来，可用于解决原子的更新数据和数据的版本号，可以解决使用 CAS 进行原子更新时可能出现的 ABA 问题。

**对象的属性修改类型**

- `AtomicIntegerFieldUpdater`:原子更新整型字段的更新器
- `AtomicLongFieldUpdater`：原子更新长整型字段的更新器
- `AtomicReferenceFieldUpdater`：原子更新引用类型里的字段

#### 原理

`AtomicInteger` 类主要利用 **CAS (compare and swap) + volatile** 和 native 方法来保证原子操作，从而避免 synchronized 的高开销，执行效率大为提升

### 线程池

#### 使用线程池的好处

- **降低资源消耗**。通过重复利用已创建的线程**降低线程创建和销毁造成的消耗**
- **提高响应速度**。当任务到达时，任务可以**不需要等到线程创建**就能立即执行
- **提高线程的可管理性**。线程是稀缺资源，如果无限制的创建，不仅会消耗系统资源，还会降低系统的稳定性，使用线程池可以进行**统一分配，调优和监控**

#### 线程池参数

- **`corePoolSize` :** 核心线程数定义了最小可以同时运行的线程数量

- **`workQueue`:** 当新任务来的时候会先判断当前运行的线程数量是否达到核心线程数，如果达到的话，新任务就会被存放在队列中

  > 有哪些工作队列
  >
  > 1、ArrayBlockingQueue
  > 是一个基于数组结构的**有界阻塞队列**，此队列按 FIFO（先进先出）原则对元素进行排序。
  > 2、LinkedBlockingQueue
  > 一个基于链表结构的**阻塞队列**，此队列按FIFO （先进先出） 排序元素，吞吐量通常要高于 ArrayBlockingQueue。静态工厂方法 Executors.newFixedThreadPool() 和 newSingleThreadExecutor() 使用了这个队列
  > 3、SynchronousQueue
  > 一个不存储元素的**阻塞队列**。**每个插入操作必须等到另一个线程调用移除操作**，否则插入操作一直处于阻塞状态，吞吐量通常要高于 LinkedBlockingQueue，静态工厂方法 Executors.newCachedThreadPool() 使用了这个队列。
  > 4、PriorityBlockingQueue
  > 一个具有优先级的**无限阻塞队列**。
  >
  > **LinkedBlockingQueue和ArrayBlockingQueue的区别**
  >
  > - **是否有界**：ArrayBlockingQueue是有界的，而LinkedBlockingQueue默认是无界的
  > - **锁**：ArrayBlockingQueue内部使用1个锁来控制队列项的插入、取出操作，而LinkedBlockingQueue则是使用了2个锁来控制，一个名为putLock，另一个是takeLock，但是锁的本质都是ReentrantLock。因为LinkedBlockingQueue使用了2个锁的情况下，所以在一定程度上LinkedBlockingQueue能更好支持高并发的场景操作

- **`maximumPoolSize` :** 当队列中存放的任务达到队列容量的时候，当前可以同时运行的线程数量变为最大线程数

- **`keepAliveTime`**:当线程池中的线程数量大于 `corePoolSize` 的时候，如果这时没有新的任务提交，核心线程外的线程不会立即销毁，而是会等待，直到等待的时间超过了 `keepAliveTime`才会被回收销毁

#### 线程池的饱和策略

- **`ThreadPoolExecutor.AbortPolicy`：** 抛出 `RejectedExecutionException`来**抛弃新任务的处理并丢出异常**
- **`ThreadPoolExecutor.DiscardPolicy`：** 不处理新任务，直接**丢弃**掉不抛出异常
- **`ThreadPoolExecutor.DiscardOldestPolicy`：** 此策略将丢弃**最早的未处理的任务**请求，然后重新提交被拒绝的任务
- **`ThreadPoolExecutor.CallerRunsPolicy`：** 由调用线程处理该任务。如果**应用程序可以承受此延迟并且要求任何一个任务请求都要被执行**的话，可以选择这个策略

#### 线程池原理

![图解线程池实现原理](https://guide-blog-images.oss-cn-shenzhen.aliyuncs.com/javaguide/%E5%9B%BE%E8%A7%A3%E7%BA%BF%E7%A8%8B%E6%B1%A0%E5%AE%9E%E7%8E%B0%E5%8E%9F%E7%90%86.png)

#### 如何确定线程池大小

如果我们设置的线程池数量太小的话，如果**同一时间有大量任务/请求需要处理，可能会导致大量的请求/任务在任务队列中排队等待执行，甚至会出现任务队列满了之后任务/请求无法处理的情况，或者大量任务堆积在任务队列导致 OOM**。这样很明显是有问题的！ CPU 根本没有得到充分利用。

但是，如果我们设置**线程数量太大，大量线程可能会同时在争取 CPU 资源，这样会导致大量的上下文切换，从而增加线程的执行时间，影响了整体执行效率**

有一个简单并且适用面比较广的公式：

- **CPU 密集型任务(N+1)：** 这种任务消耗的主要是 CPU 资源，可以将线程数设置为 N（CPU 核心数）+1，比 CPU 核心数多出来的一个线程是为了防止线程偶发的缺页中断，或者其它原因导致的任务暂停而带来的影响。一旦任务暂停，CPU 就会处于空闲状态，而在这种情况下多出来的一个线程就可以充分利用 CPU 的空闲时间。
- **I/O 密集型任务(2N)：** 这种任务应用起来，系统会用大部分的时间来处理 I/O 交互，而线程在处理 I/O 的时间段内不会占用 CPU 来处理，这时就可以将 CPU 交出给其它线程使用。因此在 I/O 密集型任务的应用中，我们可以多配置一些线程，具体的计算方法是 2N

### AQS

AQS 的全称为 `AbstractQueuedSynchronizer` ，翻译过来的意思就是**抽象队列同步器**。AQS 就是一个抽象类，**主要用来构建锁和同步器**。AQS 为构建锁和同步器提供了一些通用功能的是实现，因此，使用 AQS 能简单且高效地构造出应用广泛的大量的同步器，比如我们提到的`ReentrantLock`，`Semaphore`

#### AQS原理

AQS 核心思想是，如果被请求的共享资源空闲，则将当前请求资源的线程设置为有效的工作线程，并且将共享资源设置为锁定状态。如果被请求的共享资源被占用，那么就需要一套**线程阻塞等待以及被唤醒时锁分配的机制**，这个机制 AQS 是用 **CLH 队列锁** 实现的，即将暂时获取不到锁的线程加入到**队列**中。

CLH(Craig,Landin,and Hagersten) 队列是一个虚拟的双向队列（虚拟的双向队列即不存在队列实例，仅存在结点之间的关联关系）。AQS 是将每条请求共享资源的线程封装成一个 CLH 锁队列的一个结点（Node）来实现锁的分配。

![img](https://my-blog-to-use.oss-cn-beijing.aliyuncs.com/Java%20%E7%A8%8B%E5%BA%8F%E5%91%98%E5%BF%85%E5%A4%87%EF%BC%9A%E5%B9%B6%E5%8F%91%E7%9F%A5%E8%AF%86%E7%B3%BB%E7%BB%9F%E6%80%BB%E7%BB%93/CLH.png)

#### Semaphore

`synchronized` 和 `ReentrantLock` 都是一次只允许一个线程访问某个资源，而`Semaphore`(信号量)可以用来**控制同时访问特定资源的线程数量（多个线程访问多个共享资源）**

**Semaphore的原理**

`Semaphore` 是**共享锁**的一种实现，它默认构造 AQS 的 `state` 值为 `permits`，你可以将 `permits` 的值理解为许可证的数量，只有拿到许可证的线程才能执行。

调用`semaphore.acquire()` ，线程尝试获取许可证，如果 `state >= 0` 的话，则表示可以获取成功。如果获取成功的话，使用 CAS 操作去修改 `state` 的值 `state = state - 1`。如果 `state < 0` 的话，则表示许可证数量不足。此时会创建一个 Node 节点加入阻塞队列，挂起当前线程

#### CountDownLatch 

`CountDownLatch` **允许 `count` 个线程阻塞在一个地方，等待所有线程完成倒计时**。

`CountDownLatch` 是一次性的，计数器的值只能在构造方法中初始化一次，之后没有任何机制再次对其设置值，当 `CountDownLatch` 使用完毕后，它不能再次被使用

**CountDownLatch 的原理**

`CountDownLatch` 是**共享锁**的一种实现,它默认构造 AQS 的 `state` 值为 `count`。当线程使用 `countDown()` 方法时,其实使用了`tryReleaseShared`方法以 CAS 的操作来减少 `state`,直至 `state` 为 0 。当调用 `await()` 方法的时候，如果 `state` 不为 0，那就证明任务还没有执行完毕，`await()` 方法就会一直阻塞，也就是说 `await()` 方法之后的语句不会被执行。然后，`CountDownLatch` 会自旋 CAS 判断 `state == 0`，如果 `state == 0` 的话，就会释放所有等待的线程，`await()` 方法之后的语句得到执行

**CountDownLatch的一个应用场景**

读取处理 6 个文件，这 6 个任务都是没有执行顺序依赖的任务，但是需要返回给用户的时候将这几个文件的处理的结果进行统计整理。

为此定义了一个线程池和 count 为 6 的`CountDownLatch`对象 。使用线程池处理读取任务，每一个线程处理完之后就将 count-1，调用`CountDownLatch`对象的 `await()`方法，直到所有文件读取完之后，才会接着执行后面的逻辑。

伪代码：

```java
public class CountDownLatchExample1 {
    // 处理文件的数量
    private static final int threadCount = 6;

    public static void main(String[] args) throws InterruptedException {
        // 创建一个具有固定线程数量的线程池对象（推荐使用构造方法创建）
        ExecutorService threadPool = Executors.newFixedThreadPool(10);
        final CountDownLatch countDownLatch = new CountDownLatch(threadCount);
        for (int i = 0; i < threadCount; i++) {
            final int threadnum = i;
            threadPool.execute(() -> {
                try {
                    //处理文件的业务操作
                    //......
                } catch (InterruptedException e) {
                    e.printStackTrace();
                } finally {
                    //表示一个文件已经被完成
                    countDownLatch.countDown();
                }
            });
        }
        countDownLatch.await();
        threadPool.shutdown();
        System.out.println("finish");
    }
}
```

#### CyclicBarrier

`CyclicBarrier` 和 `CountDownLatch` 非常类似，它也可以实现线程间的技术等待，但是它的功能比 `CountDownLatch` 更加复杂和强大。主要应用场景和 `CountDownLatch` 类似。可以多次使用。

## JVM

### Java 内存区域

**线程私有的：**

- 程序计数器

  字节码解释器通过改变程序计数器来依次读取指令，从而实现代码的流程控制，如：顺序执行、选择、循环、异常处理。

  在多线程的情况下，程序计数器用于记录当前线程执行的位置，从而当线程被切换回来的时候能够知道该线程上次运行到哪儿了

- 虚拟机栈

  线程创建时就会分配一个栈空间，线程结束后栈空间被回收。栈中元素用于支持虚拟机进行方法调用，每个方法在执行时都会创建一个**栈帧**，存储方法的局部变量表、操作栈、动态链接和返回地址等信息。

  虚拟机栈会产生两类异常：

  - StackOverflowError：线程请求的栈深度大于虚拟机允许的深度抛出
  - OutOfMemoryError：如果 JVM 栈容量可以动态扩展，虚拟机栈占用内存超出抛出

  产生异常时栈帧销毁

- 本地方法栈

  本地方法栈与虚拟机栈作用相似，不同的是虚拟机栈为虚拟机执行 Java 方法服务，本地方法栈为本地方法服务

**线程共享的：**

- 堆

  Java 虚拟机所管理的内存中最大的一块，Java 堆是所有线程共享的一块内存区域，在虚拟机启动时创建。**此内存区域的唯一目的就是存放对象实例，几乎所有的对象实例以及数组都在这里分配内存**。

- 方法区

  方法区用于存储被虚拟机加载的类信息、常量、静态变量等数据。

  JDK6之前使用永久代实现方法区，容易内存溢出。JDK7 把放在永久代的字符串常量池、静态变量等移出，JDK8 中抛弃永久代，改用在本地内存中实现的元空间来实现方法区，把 JDK 7 中永久代内容移到元空间。

  ![HotSpot 虚拟机方法区的两种实现](https://guide-blog-images.oss-cn-shenzhen.aliyuncs.com/github/javaguide/java/jvm/method-area-implementation.png)

- 直接内存 (非运行时数据区的一部分)

### JMM 内存模型

MM(Java内存模型)主要定义了对于一个共享变量，当另一个线程对这个共享变量执行写操作后，这个线程对这个共享变量的可见性

![JMM(Java 内存模型)](https://guide-blog-images.oss-cn-shenzhen.aliyuncs.com/github/javaguide/java/concurrent/jmm.png)

从上图来看，线程 1 与线程 2 之间如果要进行通信的话，必须要经历下面 2 个步骤：

1. 线程 1 把本地内存中修改过的共享变量副本的值同步到主内存中去。
2. 线程 2 到主存中读取对应的共享变量的值。

**happens-before 规则**

happens-before 这个概念来描述两个操作之间的内存可见性

- **程序顺序规则** ：一个线程内，按照代码顺序，书写在前面的操作 happens-before 于书写在后面的操作；
- **解锁规则** ：解锁 happens-before 于加锁；
- **volatile 变量规则** ：对一个 volatile 变量的写操作 happens-before 于后面对这个 volatile 变量的读操作。说白了就是对 volatile 变量的写操作的结果对于发生于其后的任何操作都是可见的。
- **传递规则** ：如果 A happens-before B，且 B happens-before C，那么 A happens-before C；
- **线程启动规则** ：Thread 对象的 `start()`方法 happens-before 于此线程的每一个动作。

### JVM 垃圾回收

#### 对象分配和回收原则

- **对象优先在 Eden 区分配**，空间分配担保是为了确保在 Minor GC 之前老年代本身还有容纳新生代所有对象的剩余空间当 Eden 区没有足够空间进行分配时，虚拟机将发起一次 Minor GC
- **大对象直接进入老年代**，大对象就是需要大量连续内存空间的对象（比如：字符串、数组）
- **长期存活的对象将进入老年代**，大部分情况，对象都会首先在 Eden 区域分配。如果对象在 Eden 出生并经过第一次 Minor GC 后仍然能够存活，并且能被 Survivor 容纳的话，将被移动到 Survivor 空间（s0 或者 s1）中，并将对象年龄设为 1(Eden 区->Survivor 区后对象的初始年龄变为 1)。对象在 Survivor 中每熬过一次 MinorGC,年龄就增加 1 岁，当它的年龄增加到一定程度，就会被晋升到老年代中

#### 主要进行 GC 的区域

**部分收集 (Partial GC)**：

- 新生代收集（Minor GC）：只对新生代进行垃圾收集；
- 老年代收集（Major GC）：只对老年代进行垃圾收集。需要注意的是 Major GC 在有的语境中也用于指代整堆收集；
- 混合收集（Mixed GC）：对整个新生代和部分老年代进行垃圾收集。

**整堆收集 (Full GC)**：收集整个 Java 堆和方法区

#### 空间分配担保

空间分配担保是为了确保在 Minor GC 之前老年代本身还有容纳新生代所有对象的剩余空间

> 之后的规则变为只要老年代的连续空间大于新生代对象总大小或者历次晋升的平均大小，就会进行 Minor GC，否则将进行 Full GC

#### 死亡对象判断方法

**引用计数法**

给对象中添加一个引用计数器：

- 每当有一个地方引用它，计数器就加 1；
- 当引用失效，计数器就减 1；
- 任何时候计数器为 0 的对象就是不可能再被使用的。

这个方法实现简单，效率高，但是目前主流的虚拟机中并没有选择这个算法来管理内存，其最主要的原因是它**很难解决对象之间相互循环引用的问题。**

**可达性分析算法**

这个算法的基本思想就是通过一系列的称为 **“GC Roots”** 的对象作为起点，从这些节点开始向下搜索，节点所走过的路径称为引用链，当一个对象到 GC Roots 没有任何引用链相连的话，则证明此对象是不可用的，需要被回收

**哪些对象可以作为 GC Roots 呢？**

- 虚拟机栈(栈帧中的本地变量表)中引用的对象
- 本地方法栈(Native 方法)中引用的对象
- 方法区中类静态属性引用的对象
- 方法区中常量引用的对象
- 所有被同步锁持有的对象

#### 引用类型

- **强引用**：如果一个对象具有强引用，那就类似于必不可少的生活用品，垃圾回收器**绝不会回收它**。当内存空间不足，Java 虚拟机宁愿抛出 OutOfMemoryError 错误，使程序异常终止，也不会靠随意回收具有强引用的对象来解决内存不足问题

- **软引用**：如果一个对象只具有软引用，那就类似于可有可无的生活用品。如果**内存空间足够，垃圾回收器就不会回收它，如果内存空间不足了，就会回收这些对象的内存**。只要垃圾回收器没有回收它，该对象就可以被程序使用

- **弱引用**：弱引用与软引用的区别在于：只具有弱引用的对象拥有更短暂的生命周期。**在垃圾回收器线程扫描它所管辖的内存区域的过程中，一旦发现了只具有弱引用的对象，不管当前内存空间足够与否，都会回收它的内存**。不过，由于垃圾回收器是一个优先级很低的线程， 因此不一定会很快发现那些只具有弱引用的对象

- **虚引用**："虚引用"顾名思义，就是形同虚设，与其他几种引用都不同，虚引用并不会决定对象的生命周期。如果一个对象仅持有虚引用，那么它就和没有任何引用一样，在任何时候都可能被垃圾回收

  在程序设计中一般很少使用弱引用与虚引用，使用软引用的情况较多，这是因为**软引用可以加速 JVM 对垃圾内存的回收速度，可以维护系统的运行安全，防止内存溢出（OutOfMemory）等问题的产生**

#### 判断无用的类

方法区主要回收的是无用的类

类需要同时满足下面 3 个条件才能算是 **“无用的类”** ：

- 该类所有的实例都已经被回收，也就是 Java 堆中不存在该类的任何实例。
- 加载该类的 `ClassLoader` 已经被回收。
- 该类对应的 `java.lang.Class` 对象**没有在任何地方被引用**，无法在任何地方**通过反射**访问该类的方法。

虚拟机可以对满足上述 3 个条件的无用类进行回收，仅仅是“可以”，而并不是和对象一样不使用了就会必然被回收

#### 垃圾收集算法

**标记-清除算法**

该算法分为“标记”和“清除”阶段：首先标记出所有不需要回收的对象，在标记完成后统一回收掉所有没有被标记的对象。存在空间和效率问题

**标记-复制算法**

它可以将内存**分为大小相同的两块**，每次使用其中的一块。当这一块的内存使用完后，就将还存活的对象**复制到另一块去**，然后再把使用的空间一次清理掉。这样就使每次的内存回收都是对内存区间的一半进行回收

**标记-整理算法**

根据老年代的特点提出的一种标记算法，标记过程仍然与“标记-清除”算法一样，但后续步骤不是直接对可回收对象回收，而是让所有存活的对象向一端移动，然后直接清理掉端边界以外的内存

**分代收集算法**

比如在新生代中，每次收集都会有大量对象死去， 所以可以选择”标记-复制“算法，**只需要付出少量对象的复制成本就可以完成每次垃圾收集**。而老年代的对象存活几率是比较高的，而且没有额外的空间对它进行分配担保，所以我们必须选择“标记-清除”或“标记-整理”算法进行垃圾收集

#### 垃圾收集器

**Serial 收集器**

只使用一条垃圾收集线程去完成垃圾收集工作，更重要的是它在进行垃圾收集工作的时候必须暂停其他所有的工作线程（ **"Stop The World"** ），直到它收集结束

新生代采用标记-复制算法，老年代采用标记-整理算法。优点是简单高效

**Parnew 收集器**

Serial 收集器的多线程版本。

**Parallel Scavenge 收集器**

Parallel Scavenge 收集器关注点是吞吐量（高效率的利用 CPU）。CMS 等垃圾收集器的关注点更多的是用户线程的停顿时间（提高用户体验）。所谓吞吐量就是 CPU 中用于运行用户代码的时间与 CPU 总消耗时间的比值。**新生代采用标记-复制算法，老年代采用标记-整理算法。**

**CMS 收集器**

CMS（Concurrent Mark Sweep）收集器是一种以**获取最短回收停顿时间为目标**的收集器。它非常符合在注重用户体验的应用上使用。

CMS 收集器是 HotSpot 虚拟机**第一款真正意义上的并发收集器**，它第一次实现了让垃圾收集线程与用户线程（基本上）同时工作。

从名字中的**Mark Sweep**这两个词可以看出，CMS 收集器是一种 **“标记-清除”算法**实现的，它的运作过程相比于前面几种垃圾收集器来说更加复杂一些。整个过程分为四个步骤：

- **初始标记：** 暂停所有的其他线程，并**记录下直接与 root 相连的对象**，速度很快 ；
- **并发标记：** 同时开启 GC 和用户线程，**用一个闭包结构去记录可达对象**。但在这个阶段结束，这个闭包结构并**不能保证包含当前所有的可达对象**。因为用户线程可能会不断的更新引用域，所以 GC 线程无法保证可达性分析的实时性。所以这个算法里会跟踪记录这些发生引用更新的地方。
- **重新标记：** 重新标记阶段就是**为了修正并发标记期间因为用户程序继续运行而导致标记产生变动的那一部分对象的标记记录**，这个阶段的停顿时间一般会比初始标记阶段的时间稍长，远远比并发标记阶段时间短
- **并发清除：** 开启用户线程，同时 GC 线程开始对未标记的区域做清扫。

![CMS 垃圾收集器 ](https://javaguide.cn/assets/CMS%E6%94%B6%E9%9B%86%E5%99%A8.8a4d0487.png)

**G1 收集器**

G1 (Garbage-First) 是一款**面向服务器**的垃圾收集器,**主要针对配备多颗处理器及大容量内存的机器. 以极高概率满足 GC 停顿时间要求的同时,还具备高吞吐量性能特征**

**特点**

**并行与并发**：G1 能充分利用 CPU、多核环境下的硬件优势，**使用多个 CPU（CPU 或者 CPU 核心）来缩短 Stop-The-World 停顿时间**。部分其他收集器原本需要停顿 Java 线程执行的 GC 动作，G1 收集器仍然可以通过并发的方式让 java 程序继续执行

**分代收集**：虽然 G1 可以不需要其他收集器配合就能独立管理整个 GC 堆，但是还是保留了分代的概念

**空间整合**：与 CMS 的“标记-清理”算法不同，G1 从**整体来看是基于“标记-整理”算法实现的收集器；从局部上来看是基于“标记-复制”算法实现的**。

**可预测的停顿**：这是 G1 相对于 CMS 的另一个大优势，降低停顿时间是 G1 和 CMS 共同的关注点，但 G1 **除了追求低停顿外，还能建立可预测的停顿时间模型**，能让使用者明确指定在一个长度为 M 毫秒的时间片段内

G1 收集器的运作大致分为以下几个步骤：

- **初始标记**
- **并发标记**
- **最终标记**
- **筛选回收**

**G1 收集器在后台维护了一个优先列表，每次根据允许的收集时间，优先选择回收价值最大的 Region(这也就是它的名字 Garbage-First 的由来)** 。这种使用 Region 划分内存空间以及有优先级的区域回收方式，保证了 G1 收集器在有限时间内可以尽可能高的收集效率（把内存化整为零）

### 类加载

#### 类加载过程

- **加载**：
  
  - 通过**全类名**获取定义此**类的二进制字节流**
  - 将字节流所代表的**静态存储结构**转换为**方法区的运行时数据结构**
  - 在**内存中生成一个代表该类的 `Class` 对象**，作为方法区这些数据的访问入口
  
- **验证**：对文件格式（复合 class 文件规范），元数据（语义分析），字节码（语法分析），符号引用等验证正确性

- **准备**：为**类变量（static 变量）**分配内存并设置类变量初始值的阶段

- **解析**：解析阶段是虚拟机将常量池内的**符号引用替换为直接引用**的过程，也就是得到类或者字段、方法在内存中的指针或者偏移量

- **初始化**：初始化阶段是执行初始化方法 `<clinit> ()`（类构造器中）方法的过程，是类加载的最后一步，这一步 JVM 才开始真正执行类中定义的 Java 程序代码(字节码)

  > 何时触发类的初始化
  >
  > 1. 使用 new 关键字实例化对象的时候；
  > 2. 读取或设置一个类的静态字段（被final修饰，已在编译器把结果放入常量池的静态字段除外）的时候；
  > 3. 调用一个类的静态方法的时候。

#### 类加载器

- **BootstrapClassLoader(启动类加载器)** ：最顶层的加载类，由 C++实现，负责加载 `%JAVA_HOME%/lib`目录下的 jar 包和类或者被 `-Xbootclasspath`参数指定的路径中的所有类
- **ExtensionClassLoader(扩展类加载器)** ：主要负责加载 `%JRE_HOME%/lib/ext` 目录下的 jar 包和类，或被 `java.ext.dirs` 系统变量所指定的路径下的 jar 包
- **AppClassLoader(应用程序类加载器)** ：面向我们用户的加载器，负责加载当前应用 classpath 下的所有 jar 包和类

#### 双亲委派模型

在类加载的时候，系统会首先判断当前类是否被加载过。已经被加载的类会直接返回，否则才会尝试加载。加载的时候，**首先会把该请求委派给父类加载器的 `loadClass()` 处理**，因此所有的请求最终都应该传送到顶层的启动类加载器 `BootstrapClassLoader` 中。当**父类加载器无法处理时，才由自己来处理**。当父类加载器为 null 时，会使用启动类加载器 `BootstrapClassLoader` 作为父类加载器

![ClassLoader](https://my-blog-to-use.oss-cn-beijing.aliyuncs.com/2019-6/classloader_WPS%E5%9B%BE%E7%89%87.png)

**为什么使用双亲委派模型**

双亲委派模型保证了 Java 程序的**稳定运行**，可以**避免类的重复加载**（JVM 区分不同类的方式不仅仅根据类名，相同的类文件被不同的类加载器加载产生的是两个不同的类），也**保证了 Java 的核心 API 不被篡改**。如果没有使用双亲委派模型，而是每个类加载器加载自己的话就会出现一些问题，比如我们编写一个称为 `java.lang.Object` 类的话，那么程序运行的时候，系统就会出现多个不同的 `Object` 类

# 操作系统

---

## 进程管理

### 进程和线程

进程是**资源分配**的基本单位，线程是**资源调度**的基本单位。一个进程可以有多个线程，多个线程共享同个进程下的所有共享资源，每个线程有自己的**堆栈**和**局部变量**，

线程和进程最大的不同在于基本上**各进程是独立的**，而各线程则不一定，因为同一进程中的线程极有可能会相互影响。**线程执行开销小，但不利于资源的管理和保护**；而进程正相反。

### 进程有哪几种状态

- **创建状态(new)** ：进程正在被创建，尚未到就绪状态。
- **就绪状态(ready)** ：进程已处于准备运行状态，即进程**获得了除了处理器之外的一切所需资源**，一旦得到处理器资源(处理器分配的时间片)即可运行。
- **运行状态(running)** ：进程正在处理器上上运行(单核 CPU 下任意时刻只有一个进程处于运行状态)。
- **阻塞状态(waiting)** ：又称为等待状态，进程正在等待某一事件而暂停运行，如等待某资源为可用或等待 IO 操作完成。即使处理器空闲，该进程也不能运行。
- **结束状态(terminated)** ：进程正在从系统中消失。可能是进程正常结束或其他原因中断退出运行。

### 进程间的通信方式

每个进程的用户地址空间都是独立的，一般而言是不能互相访问的，但内核空间是每个进程都共享的，所以**进程之间要通信必须通过内核**。

- **管道**：实际上**内核里面的一串缓存**，分为*匿名管道*和*命名管道*。匿名管道只能用于具有亲缘关系的进程之间的通信。命名管道克服了匿名管道的缺点，以磁盘文件的方式存在，可以实现本机任意两个进程通信，并且严格遵循**先进先出（FIFO）**。优点：简单，缺点：管道通信方式**效率较低**，不适合进程间频繁地交换数据。

  > Linux 中 `|` 就是管道通信
  >
  > ```shell
  > $ ps auxf | grep mysql
  > ```
  >
  > 它的功能是将前一个命令（`ps auxf`）的输出，作为后一个命令（`grep mysql`）的输入，从这功能描述，可以看出**管道传输数据是单向的**，如果想相互通信，我们需要创建两个管道才行

- **消息队列**：消息队列是消息的链表,具有特定的格式,存放在内存中并由消息队列标识符标识。管道和消息队列的通信数据都是先进先出的原则。消息队列可以实现消息的随机查询,消息不一定要以先进先出的次序读取,也可以按消息的类型读取.比 FIFO 更有优势。优点：**消息队列克服了信号承载信息量少，管道只能承载无格式字节流以及缓冲区大小受限等缺点**，缺点：**不适合比较大数据的传输**，**存在用户态与内核态之间的数据拷贝开销**

- **共享内存**：**共享内存的机制，就是拿出一块虚拟地址空间来，映射到相同的物理内存中**，使得**多个进程可以访问同一块内存空间**，不同进程可以及时看到对方进程中对共享内存中数据的更新。这种方式**需要依靠某种同步操作**，如互斥锁和信号量等。可以说这是最有用的进程间通信方式。

- **信号量：**为了防止多进程竞争共享资源，而造成的数据错乱，所以需要保护机制，使得共享的资源，在任意时刻只能被一个进程访问。正好，**信号量**就实现了这一保护机制。**信号量其实是一个整型的计数器，主要用于实现进程间的互斥与同步，而不是用于缓存进程间通信的数据**

- **信号：**信号是一种比较复杂的通信方式，用于通知接收进程某个事件已经发生

- **套接字（socket）：**主要用于在**客户端和服务器之间通过网络进行通信**。套接字是支持 TCP/IP 的网络通信的基本操作单元，可以看做是不同主机之间的进程进行双向通信的端点

### 进程调度算法

- **先到先服务**：从就绪队列中选择一个**最先进入该队列**的进程为之分配资源，使它立即执行并一直执行到完成或发生某事件而被阻塞放弃占用 CPU 时再重新调度
- **短作业优先**：从就绪队列中选出一个估计**运行时间最短**的进程为之分配资源，使它立即执行并一直执行到完成或发生某事件而被阻塞放弃占用 CPU 时再重新调度
- **时间片轮转调度算法**：每个进程被分配一个时间段，称作它的时间片，即该进程允许运行的时间。如果时间片用完，进程还在运行，那么将会把此进程从 CPU 释放出来，并把 CPU 分配另外一个进程。如果该进程在时间片结束前阻塞或结束，则 CPU 立即进行切换
- **多级反馈队列调度算法**：前面介绍的几种进程调度的算法都有一定的局限性。如**短进程优先的调度算法，仅照顾了短进程而忽略了长进程** 。多级反馈队列调度算法**既能使高优先级的作业得到响应又能使短作业（进程）迅速完成**，因而它是目前**被公认的一种较好的进程调度算法**，UNIX 操作系统采取的便是这种调度算法
- **优先级调度**：为每个流程分配优先级，首先执行具有最高优先级的进程，依此类推。具有相同优先级的进程以 FCFS 方式执行。可以根据内存要求，时间要求或任何其他资源要求来确定优先级

### 父进程与子进程

父进程与子进程拥有独立的地址空间和 PID 参数、不同的父进程号、自己的文件描述符。**共享代码段、数据段和用户堆栈内存空间是与子进程**。**只有当子进程在运行中出现写操作时**，才会产生中断，并为子进程分配内存空间。

### 线程同步的方式

- **互斥量**：采用互斥对象机制，**只有拥有互斥对象的线程才有访问公共资源的权限**。因为互斥对象只有一个，所以可以保证公共资源不会被多个线程同时访问。比如 Java 中的 synchronized 关键词和各种 Lock 都是这种机制
- **信号量**：它**允许同一时刻多个线程访问同一资源**，但是需要控制同一时刻访问此资源的最大线程数量
- **事件**：Wait / Notify：通过通知操作的方式来保持多线程同步，还可以方便的实现多线程优先级的比较操作

### 孤儿进程和僵尸进程

- **孤儿进程**：孤儿进程是指一个父进程退出后，而它的一个或多个子进程还在运行，那么这些子进程將成为孤儿进程。孤儿进程將被 init 进程（进程号为1）所收养，并且由init EeN灭十门完整状态收集工作，孤儿进程一般不会产生任何危害

- **僵尸进程**：僵尸进程僵尸进程是指一个进程使用 fork(函数创建子进程，如果子进程退出，而父进程并没有调用 wt( 或者wtpid0 系统调用取得子进程的终止状态，那么子进程的进程描述符仍然保存在系统中，占用系统资源，这种进程称为僵尸进程

  > 解决僵尸进程一般，为了防止产生僵尸进程，在fork0 子进程之后我们都要及时在父进程中使用 wt()或者wtpid()系统调用，等子进程结束后，父进程回收子进程 PCB 的资源。同时，当子进程退出的时候，内核都会给父进程一个 SIGCHLD信号，所以可以建立一个捕获 SIGCHLD信号的信号处理函数，在函数体中调用wt() 或wtpid()， 就可以清理退出的子进程以达到防止僵尸进程的目的

### 同步、异步、互斥、阻塞、非阻塞

- **同步**：每个线程之间按预定的先后次序进行运行
- 同步与异步是对应的，它们是线程之间的关系，两个线程之间要么是同步的，要么是异步的
- **互斥**：当有若干个线程访问同一块资源时，规定同一时间只有一个线程可以得到访问权，其它线程需要等占用资源者释放该资源才可以申请访问。**线程互斥可以看成是一种特殊的线程同步**

- 阻塞与非阻塞是对同一个线程来说的，在某个时刻，线程要么处于阻塞，要么处于非阻塞

- **阻塞是使用同步机制的结果，非阻塞则是使用异步机制的结果**

### 互斥锁和自旋锁

- **互斥锁**：互斥锁也称为互斥量（Mutex），是一种用来保护临界区的特殊变量，它可以处于锁定(locked）状态，也可以处于解锁 (unlocked） 状态：

  - ﻿如果互斥锁是锁定的，就是某个特定的线程正持有这个互斥锁
  - ﻿如果没有线程持有这个互斥锁，那么这个互斥锁就处于解锁状态

  每个互斥锁内部有一个线程等待队列，用来保存等待该互斥锁的线程。当互斥锁处于解锁状态时，如果某个线程试图获取这个互斥锁，那么这个线程就可以得到这个互斥锁而不会阻塞；当互斥锁处于锁定状态时，如果某个线程试图获取这个互斥锁，那么这个线程將阻塞在互斥锁的等待队列内

- **自旋锁**：自旋锁与互斥锁类似，但它不是通过休眠使进程阻塞，而是在获取锁之前一直处于忙等（自旋）阻塞状态。自旋锁可以用于以下情况：锁被持有的时间短，而且线程并不希望在重新调度上花费太多的成本。

  自旋锁最多只能被一个可执行线程持有，如果一个执行线程试图获得一个已经被持有的自旋锁，那么该线程就会一直进行忙循环-旋转- 等待锁重新可用

### 多进程和多线程的优缺点

一个进程由PCB（进程控制块）、数据段、代码段组成，进程本身不可以运行程序，而是像一个容器一样，先创建出一个主线程，分配给主线程一定的系统资源，这时候就可以在主线程开始实现各种功能。当我们需要实现更复杂的功能时，可以在主线程里创建多个子线程，跟人多好干活的道理一样，多个线程在同一个进程里，利用这个进程所拥有的系统资源合作完成某些功能

|                            多进程                            |                            多线程                            |
| :----------------------------------------------------------: | :----------------------------------------------------------: |
| 更健壮，一个进程死了不影响其他进程，子进程死了也不会影响到主进程 | 多线程比较脆弱，一个线程崩溃很可能影响到整个程序，因为多个线程是在一个进程里一起合作干活的 |
|              性能高，每个进程独立地址空间和资源              | 多个线程是一起共享了同个进程里的空间和资源，线程的性能上限一定比不上进程 |
|                          系统花销大                          |                          系统花销小                          |
|     多进程通讯因为需要跨越进程边界，不适合大量数据的传送     | 适合各线程间大量数据的传送，可以共享同一进程里的共享内存和变量 |
|       多进程逻辑控制比多线程复杂，需要与主进程做好交互       |              需要复杂的线程同步和加锁控制等机制              |

> **进程和线程的选择**：安全稳定选进程，快速频繁选线程

### 死锁

当两个线程为了保护两个不同的共享资源而使用了两个互斥锁，那么这两个互斥锁应用不当的时候，可能会造成**两个线程都在等待对方释放锁**，在没有外力的作用下，这些线程会一直相互等待，就没办法继续运行，这种情况就是发生了**死锁**。

### 死锁的必要条件

- **互斥**：资源必须处于非共享模式，即一次只有一个进程可以使用。如果另一进程申请该资源，那么必须等待直到该资源被释放为止。
- **占有并等待**：一个进程至少应该占有一个资源，并等待另一资源，而该资源被其他进程所占有。
- **非抢占**：资源不能被抢占。只能在持有资源的进程完成任务后，该资源才会被释放。
- **循环等待**：有一组等待进程 `{P0, P1,..., Pn}`， `P0` 等待的资源被 `P1` 占有，`P1` 等待的资源被 `P2` 占有，......，`Pn-1` 等待的资源被 `Pn` 占有，`Pn` 等待的资源被 `P0` 占有。

### 解决死锁的方法

- **预防死锁**：只要破坏四个必要条件中的任何一个就能够预防死锁的发生

  - 破坏“占有并等待”：静态分配策略，就是指一个进程必须在执行前就申请到它所需要的全部资源，并且知道它所要的资源都得到满足之后才开始执行
  - 破坏“循环等待”：层次分配

  > 预防死锁会导致 **低效的进程运行** 和 **资源使用率**

- **避免死锁**：银行家算法：当一个进程申请使用资源的时候，**银行家算法** 通过先 **试探** 分配给该进程资源，然后通过 **安全性算法** 判断分配后系统是否处于安全状态，若不安全则试探分配作废，让该进程继续等待，若能够进入到安全的状态，则就 **真的分配资源给该进程

  > 避免死锁也不利于各进程对系统资源的**充分共享**

- **死锁检测**：对资源的分配不加以任何限制，也不采取死锁避免措施，但系统 **定时地运行一个 “死锁检测”** 的程序，判断系统内是否出现死锁，如果检测到系统发生了死锁，再采取措施去解除它

- **死锁解除**：当死锁检测程序检测到存在死锁发生时，应设法让其解除，让系统从死锁状态中恢复过来

## 内存管理

操作系统的内存管理主要负责内存的分配与回收（malloc 函数：申请内存，free 函数：释放内存），另外地址转换也就是将逻辑地址转换成相应的物理地址等功能也是操作系统内存管理做的事情

---

### 内存管理机制

简单分为**连续分配管理方式**和**非连续分配管理方式**这两种。连续分配管理方式是指为一个用户程序分配一个连续的内存空间，常见的如 **块式管理** 。同样地，非连续分配管理方式允许一个程序使用的内存分布在离散或者说不相邻的内存中，常见的如**页式管理**和**段式管理**

- **块式管理** ： 远古时代的计算机操作系统的内存管理方式。将内存分为几个固定大小的块，每个块中只包含一个进程。如果程序运行需要内存的话，操作系统就分配给它一块，如果程序运行只需要很小的空间的话，分配的这块内存很大一部分几乎被浪费了。这些在每个块中未被利用的空间，我们称之为碎片。
- **页式管理** ：把主存分为大小相等且固定的一页一页的形式，页较小，相比于块式管理的划分粒度更小，提高了内存利用率，减少了碎片。页式管理通过页表对应逻辑地址和物理地址。
- **段式管理** ： 页式管理虽然提高了内存利用率，但是页式管理其中的页并无任何实际意义。 段式管理把主存分为一段段的，段是有实际意义的，每个段定义了一组逻辑信息，例如,有主程序段 MAIN、子程序段 X、数据段 D 及栈段 S 等。 段式管理通过段表对应逻辑地址和物理地址。

> 页是物理单位，段是逻辑单位。分页可以有效提高内存利用率，分段可以更好满足用户需求

### 页式管理

#### 快表

为了提高虚拟地址到物理地址的转换速度，操作系统在 **页表方案** 基础之上引入了 **快表** 来加速虚拟地址到物理地址的转换。我们可以把快表理解为一种特殊的高速缓冲存储器（Cache），其中的内容是页表的一部分或者全部内容。有了快表，有时只要访问一次高速缓冲存储器，一次主存，这样可加速查找并提高指令执行速度

使用快表之后的地址转换流程：

1. 根据虚拟地址中的页号查快表；
2. 如果该页在快表中，直接从快表中读取相应的物理地址；
3. 如果该页不在快表中，就访问内存中的页表，再从页表中得到物理地址，同时将页表中的该映射表项添加到快表中；当快表填满后，又要登记新页时，就按照一定的淘汰策略淘汰掉快表中的一个页。

#### 多级页表

引入多级页表的主要目的是为了避免把全部页表一直放在内存中占用过多空间，特别是那些根本就不需要的页表就不需要保留在内存中。多级页表属于时间换空间的典型场景

### 分页机制和分段机制的共同点和区别

1. 共同点：
   - 分页机制和分段机制都是为了提高内存利用率，减少内存碎片
   - 页和段都是离散存储的，所以两者都是离散分配内存的方式。但是，每个页和段中的内存是连续的
2. 区别：
   - 页的大小是固定的，由操作系统决定。而段的大小不固定，取决于我们当前运行的程序
   - 分页仅仅是为了满足操作系统内存管理的需求。而段是逻辑信息的单位，在程序中可以体现为代码段，数据段，能够更好满足用户的需要

### 段页式管理

段页式管理机制结合了段式管理和页式管理的优点。简单来说段页式管理机制就是把主存先分成若干段，每个段又分成若干页，也就是说 **段页式管理机制** 中段与段之间以及段的内部的都是离散的

### 虚拟内存

**虚拟内存**可以让程序拥有超过系统物理内存大小的可用内存空间。**虚拟内存为每个进程提供了一个一致的、私有的地址空间，它让每个进程产生了一种自己在独享主存的错觉（每个进程拥有一片连续完整的内存空间）**。这样会更加有效地管理内存并减少出错。**虚拟内存的重要意义是它定义了一个连续的虚拟地址空间**，并且 **把内存扩展到硬盘空间**

> **虚拟内存** 使得应用程序认为它拥有连续的可用的内存（一个连续完整的地址空间），而实际上，它通常是被分隔成多个物理内存碎片，还有部分暂时存储在外部磁盘存储器上，在需要时进行数据交换。与没有使用虚拟内存技术的系统相比，使用这种技术的系统使得大型程序的编写变得更容易，对真正的物理内存（例如 RAM）的使用也更有效率。

### 局部性原理

局部性原理是虚拟内存技术的基础，正是因为程序运行具有局部性原理，才可以只装入部分程序到内存就开始运行。局部性原理表现在以下两个方面：

1. **时间局部性** ：如果程序中的**某条指令**一旦执行，不久以后该指令可能再次执行；如果**某数据**被访问过，不久以后该数据可能再次被访问。产生时间局部性的典型原因，是由于在程序中存在着大量的**循环操作**
2. **空间局部性** ：一旦程序访问了**某个存储单元**，在不久之后，其附近的存储单元也将被访问，即程序在一段时间内所访问的地址，可能集中在一定的范围之内，这是因为指令通常是**顺序存放、顺序执行的，数据也一般是以向量、数组、表等形式簇聚存储的**

### 虚拟内存的实现方式

- **请求分页存储管理** ：建立在分页管理之上，为了支持虚拟存储器功能而增加了请求调页功能和页面置换功能。请求分页是目前最常用的一种实现虚拟存储器的方法。请求分页存储管理系统中，**在作业开始运行之前，仅装入当前要执行的部分段即可运行**。假如在**作业运行的过程中发现要访问的页面不在内存，则由处理器通知操作系统按照对应的页面置换算法将相应的页面调入到主存**，同时操作系统也可以将暂时不用的页面置换到外存中。
- **请求分段存储管理** ：建立在分段存储管理之上，增加了请求调段功能、分段置换功能。请求分段储存管理方式就如同请求分页储存管理方式一样，在作业开始运行之前，仅装入当前要执行的部分段即可运行；在执行过程中，可使用请求调入中断动态装入要访问但又不在内存的程序段；当内存空间已满，而又需要装入新的段时，根据置换功能适当调出某个段，以便腾出空间而装入新的段。
- **请求段页式存储管理**

> **分页存储和请求分页存储的区别**：请求分页存储管理建立在分页管理之上。他们的根本区别是是否将程序全部所需的全部地址空间都装入主存，这也是请求分页存储管理可以提供虚拟内存的原因，我们在上面已经分析过了。

### 页面置换算法

地址映射过程中，若在页面中发现所要访问的页面不在内存中，则发生缺页中断 。当发生缺页中断时，如果当前内存中并没有空闲的页面，操作系统就必须在内存选择一个页面将其移出内存，以便为即将调入的页面让出空间。用来**选择淘汰哪一页的规则叫做页面置换算法**，我们可以把页面置换算法看成是淘汰页面的规则

- **OPT 页面置换算法（最佳页面置换算法）** ：最佳(Optimal, OPT)置换算法所选择的被淘汰页面将是以后永不使用的，或者是在最长时间内不再被访问的页面,这样可以保证获得最低的缺页率。但由于人们目前无法预知进程在内存下的若千页面中哪个是未来最长时间内不再被访问的，因而该算法无法实现。一般作为衡量其他置换算法的方法。
- **FIFO（First In First Out） 页面置换算法（先进先出页面置换算法）** : 总是淘汰最先进入内存的页面，即选择在内存中驻留时间最久的页面进行淘汰。
- **LRU （Least Recently Used）页面置换算法（最近最久未使用页面置换算法）** ：LRU 算法赋予每个页面一个访问字段，用来记录一个页面自上次被访问以来所经历的时间 T，当须淘汰一个页面时，选择现有页面中其 T 值最大的，即最近最久未使用的页面予以淘汰。
- **LFU （Least Frequently Used）页面置换算法（最少使用页面置换算法）** : 该置换算法选择在之前时期使用最少的页面作为淘汰页

## Linux

### Linux 常用命令

- **cd**：切换目录
- **ls**：查看目录
- **mkdir**：创建目录 
- **cp**：复制文件或文件夹
- **mv**：移动文件或文件夹
- **rm**：删除文件或文件夹
- **ps**：查看进程情况
- **kill**：杀死进程
- **tar**：对文件进行打包
- **cat**：杳看文件内容
- **top**：查看操作系统的信息，如进程、CPU占用率、内存信息等（实时）
- **free**： 查看内存使用情况
- **pwd**：显示当前工作目录
- **grep**：通常与管道命令一起使用，用于对一些命令的输出进行筛选加工

### Linux 内核组成

主要有五个子系统组成：**进程调度、进程通信、内存管理、虚拟文件系统、网络接口**

### 内核态与用户态

- **内核态**：用户进程通过系统调用等方式运行内核的代码就处于内核态
- **用户态**：用户进程运行自己的程序代码就处于用户态

用户运行一个程序，该程序创建的进程开始时运行自己的代码，处于用户态。如果要执行文件操作、网络数据发送等操作必须通过 write、send 等**系统调用**，这些系统调用会调用内核的代码。进程会切换到 Ring 0 ，然后进入 3G - 4G 中的内核地址空间去执行内核代码来完成相应的操作。内核态的进程执行完后又会切换到 Ring3 ，回到用户态。这样，用户态的程序就不能随意操作内核地址空间

### 内核抢占

如果进程正在执行内核函数时（即它在**内核态运行**时），允许发生内核切换（被替换的进程是正在执行内核函数的进程），这个内核就是抢占的

### 内核间同步

在现代操作系统里，同一时间可能有多个内核执行流在执行，因此内核其实像多进程多线程编程一样也需要一些同步机制来同步各执行单元对共享数据的访问。尤其是在多处理器系统上，更需要一些同步机制来同步不同处理器上的执行单元对共享的数据的访问

- **原子操作**
- **信号量（semaphore）**
- **顺序锁（seqlock）**
- 读写信号量（rw_semaphore）
- 自旋锁（spinlock）
- 大内核锁（BKL，Big Kernel Lock）
- 读写锁（rwlock）
- 大读者锁（brlock-Big Reader Lock） 
- 读-拷贝修改(RCU，Read-Copy Update)

### 用户与内核通信

- **系统调用**：用户空间进程通过系统调用进入内核空间，访问指定的内核空间数据
- **驱动程序**：用户空间进程可以使用封装后的系统调用接口访问驱动设备节点，以和运行在内核空间的驱动程序通信
- **共享内存（mmap）**：在代码中调用接口，实现内核空间与用户空间的地址映射

### 系统调用

为了**管理硬件资源和为应用程序开发人员提供良好的环境**来使应用程序具有更好的兼容性，为了达到这个目的，内核**提供一系列具备预定功能的多内核函数，通过一组称为系统调用（system call)的接口呈现给用户**。系统调用把应用程序的请求传给内核，调用相应的的内核函数完成所需的处理，将处理结果返回给应用程序

## OS 其他常见问题

### 程序从开始到结束运行的过程

- **预处理**：预处理指令，引入头文件，去除注释，处理所有的条件编译指令，宏的替换，添加行号，保留所有的编译器指令
- **编译**：.c 文件 -> .obg 文件。对预处理后的文件进行语法分析，词法分析，语义分析，符号汇总，然后**生成汇编代码**
- **汇编**：将汇编代码转成二进制文件
- **链接**：引入库文件或者其他源文件的变量或者函数等。分为静态链接和动态链接

### 硬链接和软链接的区别

**硬链接**：新建的文件是已经存在的文件的一个别名，当原文件删除时，新建的文件仍然可以使用

**软链接**：也称为符号链接，新建的文件以“路径”的形式来表示另一个文件，和Windows的快捷方式十分相似，新建的软链接可以指向不存在的文件

两者区别：

- 原理上，硬链接和源文件的inode节点号相同，两者互为硬链接。软连接和源文件的inode节点号不同，进而指向的block也不同，软连接block中存放了源文件的路径名。 实际上，硬链接和源文件是同一份文件，而软连接是独立的文件，类似于快捷方式，存储着源文件的位置信息便于指向

  > **inode** ：文件存储在了块（block）中，但是还需要一个空间来存储文件的 **元信息 metadata**（某个文件被分成几块、每一块的地址、文件拥有者，创建时间，权限，大小），**存储文件元信息的区域就叫 inode**。可以使用 stat 命令查看 inode 信息
  >
  > **block** ：实际文件的内容，如果一个文件大于一个块时候，那么将占用多个 block，但是一个块只能存放一个文件。（因为数据是由 inode 指向的，如果有两个文件的数据存放在同一个块中，就会乱套了）

- 若原文件删除了，则该软连接则不可以访问，而硬连接则是可以的

- 由于符号链接的特性，导致其可以跨越磁盘分区，但硬链接不具备这个特性

### 内存泄漏和内存溢出

- **内存泄漏**：是指用户申请了内存后不进行归还，结果无法再被访问，操作系统也无法再将此块内存分给其他程序
- **内存溢出**：申请或使用内存超出了系统分配的内存范围

### 栈内存和堆内存的区别

栈内存：在执行函数时，函数参数，局部变量（包括 const 局部变量），函数调用后返回的地址都在栈上创建，**函数执行结束时这些存储单元自动被释放。栈内存分配运算内置于处理器的指令集中，效率很高，但是分配的内存容量有限**

堆内存：亦称**动态内存分配**。程序在运行的时候用 malloc 或 new 申请任意大小的内存，程序员自己负责在适当的时候用 free 或 delete释放内存。动态内存的生存期可以由我们决定，如果我们不释放内存，程序将在最后才释放掉动态内存。 但是，良好的编程习惯是：如果某动态内存不再使用，需要将其释放掉，否则，我们认为发生了内存泄漏现象

### 中断和异常

# 计算机网络

## 网络基础

### OSI 七层网络模型和 TCP/IP 四层网络模型

- **OSI 七层网络模型**

![OSI 七层网络模型](/Users/dalang/Pictures/c++/osi-7-model.png)

- **TCP/IP 四层网络模型**
  1. 应用层：SMTP、HTTP、Telnet 、FTP
  2. 传输层：TCP、UDP
  3. 网络层：ARP、ICMP（网际控制报文协议：一种错误报告协议，当网络问题阻止 IP 数据包的传递时，网络设备(如路由器)使用该协议向源 IP 地址生成错误信息）、DHCP（动态主机配置协议：自动提供 IP 地址和其他相关配置信息(如子网掩码和默认网关)的 Internet 协议(IP)主机）
  4. 网络接口层：

![TCP/IP 四层网络模型](/Users/dalang/Pictures/c++/tcp-ip-4-model.png)

- **OSI 七层模型为什么干不过 TCP/IP 四 层模型**
  - OSI 的协议实现起来过分复杂，而且**运行效率很低**
  - OSI 的层次划分不太合理，**有些功能在多个层次中重复出现**
  - OSI 制定标准的周期太长

### 计算机网络分层的原因

- **各层之间相互独立**：各层之间相互独立，各层之间不需要关心其他层是如何实现的，只需要知道自己如何调用下层提供好的功能就可以了（可以简单理解为接口调用）**。这个和我们对开发时系统进行分层是一个道理**
- **提高了整体灵活性** ：每一层都可以使用最适合的技术来实现，你只需要保证你提供的功能以及暴露的接口的规则没有改变就行了。**这个和我们平时开发系统的时候要求的高内聚、低耦合的原则也是可以对应上的**
- **问题化小** ： 分层可以将复杂的网络间题分解为许多比较小的、界线比较清晰简单的小问题来处理和解决。 **这个和我们平时开发的时候，一般会将系统功能分解，然后将复杂的问题分解为容易理解的更小的问题是相对应的，这些较小的问题具有更好的边界（目标和接口）定义**

## TCP 与 UCP

### TCP 与 UDP 的区别

|                            |                             TCP                              |                             UDP                              |
| :------------------------: | :----------------------------------------------------------: | :----------------------------------------------------------: |
|      **是否面向连接**      | TCP 提供面向连接的服务，在传送数据之前必须先建立连接，数据传送结束后要释放连接 |              UDP 在传送数据之前不需要先建立连接              |
|     **是否是可靠传输**     | TCP 提供可靠的传输服务，TCP 在传递数据之前，会有三次握手来建立连接，而且在数据传递时，有确认、窗口、重传、拥塞控制机制。通过 TCP 连接传输的数据，无差错、不丢失、不重复、并且按序到达 | 远地主机在收到 UDP 报文后，不需要给出任何确认，并且不保证数据不丢失，不保证是否顺序到达 |
|        **传输效率**        |    TCP 进行传输的时候多了连接、确认、重传等机制，效率较低    |                           效率较高                           |
|        **传输形式**        |                          面向字节流                          |                           面向报文                           |
| **是否提供广播或多播服务** |                       只支持点对点通信                       |              支持一对一、一对多、多对一、多对多              |

### TCP 与 UDP 的应用场景

- **UDP 一般用于即时通信**，比如： 语音、 视频 、直播等等。这些场景对传输数据的准确性要求不是特别高，比如你看视频即使少个一两帧，实际给人的感觉区别也不大。基于 UDP 的协议：**DHCP**（动态主机配置协议，动态配置 IP 地址）、**DNS**

- **TCP 用于对传输准确性要求特别高的场景**，比如文件传输、发送和接收邮件、远程登录等等。基于 TCP 的协议：**HTTP**、**FTP**（文件传输协议）、**SMTP**（简单邮件传输协议）、**POP3/IMAP**（负责邮件接收的协议）、**Telent**（远程登陆协议）、**SSH**

  > **HTTP 协议是基于 TCP 协议的**，所以发送 HTTP 请求之前首先要建立 TCP 连接也就是要经历 3 次握手

### TCP 三次握手和四次挥手

 **三次握手的过程**：

1. 客户端发送带有 SYN（SEQ=x） 标志的数据包 -> 服务端，然后客户端进入 **SYN_SEND** 状态，等待服务器的确认
2. 服务端发送带有 SYN+ACK(SEQ=y,ACK=x+1) 标志的数据包 –> 客户端,然后服务端进入 **SYN_RECV** 状态
3. 客户端发送带有带有 ACK(ACK=y+1) 标志的数据包 –> 服务端，然后客户端和服务器端都进入**ESTABLISHED** 状态，完成TCP三次握手

**为什么要三次握手**

1. **第一次握手** ：Client 什么都不能确认；Server 确认了对方发送正常，自己接收正常

2. **第二次握手** ：Client 确认了：自己发送、接收正常，对方发送、接收正常；Server 确认了：对方发送正常，自己接收正常

3. **第三次握手** ：Client 确认了：自己发送、接收正常，对方发送、接收正常；Server 确认了：自己发送、接收正常，对方发送、接收正常

   > 三次握手的目的是建立可靠的通信信道，说到通讯，简单来说就是数据的发送与接收，而三次握手最主要的目的就是双方确认自己与对方的发送与接收是正常的

**第2次握手传回了ACK，为什么还要传回SYN**

服务端传回发送端所发送的 ACK 是为了告诉客户端：“我接收到的信息确实就是你所发送的信号了”，这表明从客户端到服务端的通信是正常的。回传 SYN 则是为了建立并确认从服务端到客户端的通信

**四次挥手过程**

1. **第一次挥手** ：客户端发送一个 FIN（SEQ=X） 标志的数据包->服务端，用来关闭客户端到服务器的数据传送。然后，客户端进入 **FIN-WAIT-1** 状态。
2. **第二次挥手** ：服务器收到这个 FIN（SEQ=X） 标志的数据包，它发送一个 ACK （SEQ=X+1）标志的数据包->客户端 。然后，此时服务端进入**CLOSE-WAIT**状态，客户端进入**FIN-WAIT-2**状态。
3. **第三次挥手** ：服务端关闭与客户端的连接并发送一个 FIN (SEQ=y)标志的数据包->客户端请求关闭连接，然后，服务端进入**LAST-ACK**状态。
4. **第四次挥手** ：客户端发送 ACK (SEQ=y+1)标志的数据包->服务端并且进入**TIME-WAIT**状态，服务端在收到 ACK (SEQ=y+1)标志的数据包后进入 CLOSE 状态。此时，如果客户端等待 **2MSL** 后依然没有收到回复，就证明服务端已正常关闭，随后，客户端也可以关闭连接了

**为什么要四次挥手**

1. **第一次挥手** ： A 说“我没啥要说的了”

2. **第二次挥手** ：B 回答“我知道了”，但是 B 可能还会有要说的话，A 不能要求 B 跟着自己的节奏结束通话

3. **第三次挥手** ：于是 B 可能又巴拉巴拉说了一通，最后 B 说“我说完了”

4. **第四次挥手** ：A 回答“知道了”，这样通话才算结束

   > TCP是全双工通信，可以双向传输数据。任何一方都可以在数据传送结束后发出连接释放的通知，待对方确认后进入半关闭状态。当另一方也没有数据再发送的时候，则发出连接释放通知，对方确认后就完全关闭了 TCP 连接

**为什么不能把服务器发送的 ACK 和 FIN 合并起来，变成三次挥手**

因为服务器收到客户端断开连接的请求时，可能还有一些数据没有发完，这时先回复 ACK，表示接收到了断开连接的请求。等到数据发完之后再发 FIN，断开服务器到客户端的数据传送

**如果第二次挥手时服务器的 ACK 没有送达客户端，会怎样**

客户端没有收到 ACK 确认，会重新发送 FIN 请求

**为什么第四次挥手客户端需要等待 2*MSL（报文段最长寿命）时间后才进入 CLOSED 状态**

第四次挥手时，客户端发送给服务器的 ACK 有可能丢失，如果服务端因为某些原因而没有收到 ACK 的话，服务端就会重发 FIN。**等待 2MSL 可保证服务端收到 ACK 并且没有重发 FIN**，此时可以进入 CLOSED 状态。

> MSL ：一个片段在网络中最大的存活时间，2MSL 就是一个发送和一个回复所需的最大时间

### TCP 如何保证传输的可靠性

1. **基于数据块传输** ：应用数据被分割成 TCP 认为最适合发送的数据块，再传输给网络层，数据块被称为报文段或段
2. **对失序数据包重新排序以及去重**：TCP 为了保证不发生丢包，就**给每个包一个序列号**，有了序列号能够将接收到的数据根据序列号排序，并且去掉重复序列号的数据就可以实现数据包去重
3. **校验和** : TCP 将**保持它首部和数据的检验和**。这是一个端到端的检验和，目的是检测数据在传输过程中的任何变化。如果收到段的检验和有差错，TCP 将丢弃这个报文段和不确认收到此报文段  
4. **超时重传** : 当发送方发送数据之后，它启动一个定时器，等待目的端确认收到这个报文段。接收端实体对已成功收到的包发回一个相应的确认信息（ACK）。如果发送端实体在合理的往返时延（RTT）内未收到确认消息，那么对应的数据包就被假设为已丢失并进行重传
5. **流量控制** : TCP 连接的每一方都有固定大小的缓冲空间，TCP 的接收端只允许发送端发送接收端缓冲区能接纳的数据。当接收方来不及处理发送方的数据，能提示发送方降低发送的速率，防止包丢失。TCP 使用的流量控制协议是可变大小的滑动窗口协议（TCP 利用滑动窗口实现流量控制）
6. **拥塞控制** : 当**网络拥塞**时，减少数据的发送

### TCP 流量控制

**TCP 利用滑动窗口实现流量控制。流量控制是为了控制发送方发送速率，保证接收方来得及接收。** 接收方发送的确认报文中的窗口字段可以用来控制发送方窗口大小，从而影响发送方的发送速率。将窗口字段设置为 0，则发送方不能发送数据

### TCP 拥塞控制

在某段时间，若**对网络中某一资源的需求超过了该资源所能提供的可用部分，网络的性能就要变坏。这种情况就叫拥塞**。拥塞控制就是**为了防止过多的数据注入到网络中**，这样就可以使网络中的路由器或链路不致过载。拥塞控制所要做的都有一个前提，就是网络能够承受现有的网络负荷。**拥塞控制是一个全局性的过程**，涉及到所有的主机，所有的路由器，以及与降低网络传输性能有关的所有因素

**TCP 实现拥塞控制的算法**

> 为了进行拥塞控制，TCP 发送方要维持一个 **拥塞窗口(cwnd)** 的状态变量。拥塞控制窗口的大小取决于网络的拥塞程度，并且动态变化。发送方让自己的发送窗口取为拥塞窗口和接收方的接受窗口中较小的一个

> 只要「发送方」没有在规定时间内接收到 ACK 应答报文，也就是**发生了超时重传，就会认为网络出现了拥塞**

- **慢开始：** 慢开始算法的思路是当主机开始发送数据时，如果立即把大量数据字节注入到网络，那么可能会引起网络阻塞，因为现在还不知道网络的符合情况。经验表明，较好的方法是先探测一下，即由小到大逐渐增大发送窗口，也就是由小到大逐渐增大拥塞窗口数值。cwnd 初始值为 1，每经过一个传播轮次，cwnd 加倍。

- **拥塞避免：** 拥塞避免算法的思路是让拥塞窗口 cwnd 缓慢增大，即每经过一个往返时间 RTT 就把发送放的 cwnd 加 1.

  **发生超时重传的拥塞发生算法**：

  ![拥塞控制流程](data:image/svg+xml,<svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 1142 873"></svg>)
  
  ![拥塞发送 —— 超时重传](https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost2/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/TCP-%E5%8F%AF%E9%9D%A0%E7%89%B9%E6%80%A7/29.jpg?image_process=watermark,text_5YWs5LyX5Y-377ya5bCP5p6XY29kaW5n,type_ZnpsdHpoaw,x_10,y_10,g_se,size_20,color_0000CD,t_70,fill_0)

**发生快速重传的拥塞发生算法**

![快速重传](data:image/svg+xml,<svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 1352 873"></svg>)

![快速重传和快速恢复](https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost4@main/%E7%BD%91%E7%BB%9C/%E6%8B%A5%E5%A1%9E%E5%8F%91%E7%94%9F-%E5%BF%AB%E9%80%9F%E9%87%8D%E4%BC%A0.drawio.png?image_process=watermark,text_5YWs5LyX5Y-377ya5bCP5p6XY29kaW5n,type_ZnpsdHpoaw,x_10,y_10,g_se,size_20,color_0000CD,t_70,fill_0)

## HTTP

### 从输入URL 到页面展示发生了什么

1. DNS 解析

   > 网址翻译成 IP 地址

   1. 检查**浏览器缓存**中是否缓存过该域名对应的 IP 地址
   2. 如果在浏览器缓存中没有找到 IP ，则将继续查找**本机系统**是否缓存过 IP
   3. 如果在本机上无法完成域名的解析，则向**本地域名解析服务系统**发起域名解析的请求
   4. 如果本地域名解析器还没有完成解析的话，那么本地域名解析服务器将**向根域名服务器发起解析请求**
   5. 根域名服务器向本地域名服务器返回 **顶级域名服务器**地址
   6. 顶级域名服务器服务器向本地域名服务器返回 **权限域名服务器**地址
   7. 权限域名服务器完成解析向本地域名服务器返回域名对应的 IP 地址

2. TCP 连接

3. 发送 HTTP 请求

4. 服务器处理请求并返回 HTTP 报文

5. 浏览器解析渲染页面

6. 连接结束

### HTTP 和 HTTPS 区别

- **端口号** ：HTTP 默认是 80，HTTPS 默认是 443

- **URL 前缀** ：HTTP 的 URL 前缀是 `http://`，HTTPS 的 URL 前缀是 `https://`

- **安全性和资源消耗** ： HTTP 协议运行在 TCP 之上，所有**传输的内容都是明文**，客户端和服务器端都无法验证对方的身份。HTTPS 是**运行在 SSL/TLS 之上的 HTTP 协议**，SSL/TLS 运行在 TCP 之上。所有**传输的内容都经过加密，加密采用对称加密，但对称加密的密钥用服务器方的证书进行了非对称加密**。所以说，**HTTP 安全性没有 HTTPS 高，但是 HTTPS 比 HTTP 耗费更多服务器资源**

  ![img](https://pic4.zhimg.com/80/v2-1ea0209a526f3527a713736fe7609fcf_1440w.webp)

### HTTP1.0 和 HTTP1.1 的区别

- **连接方式** : HTTP 1.0默认使用的是短连接，也就是每次请求都要重新建立一次连接。HTTP 是基于 TCP/IP 协议的，每一次建立或者断开连接，都需要三次握手四次挥手的开销，如果每次请求都要这样的话，开销会比较大，因此最好能维持一个长连接，可以用长连接来发多个请求。HTTP 1.1 支持长连接。**如果维持连接，那么 SSL 的开销也可以避免**

  > HTTP 1.1 单个 TCP 连接在同一时刻只能处理一个请求。HTTP 2 提供了 Multiplexing 多路传输特性，可以在一个 TCP 连接中同时完成多个 HTTP 请求。

- **状态响应码** : HTTP/1.1中新加入了大量的状态码，光是错误响应状态码就新增了24种。比如说，`100 (Continue)`——在请求大资源前的预热请求，`206 (Partial Content)`——范围请求的标识码，`409 (Conflict)`——请求与当前资源的规定冲突，`410 (Gone)`——资源已被永久转移，而且没有任何已知的转发地址。
- **缓存处理** : 在 HTTP1.0 中主要使用 header 里的 If-Modified-Since,Expires 来做为缓存判断的标准，HTTP1.1 则引入了更多的缓存控制策略例如 Entity tag，If-Unmodified-Since, If-Match, If-None-Match 等更多可供选择的缓存头来控制缓存策略。
- **带宽优化及网络连接的使用** :HTTP1.0 中，存在一些浪费带宽的现象，例如客户端只是需要某个对象的一部分，而服务器却将整个对象送过来了，并且不支持断点续传功能，HTTP1.1 则在请求头引入了 range 头域，它允许只请求资源的某个部分，即返回码是 206（Partial Content），这样就方便了开发者自由的选择以便于充分利用带宽和连接。
- **Host 头处理** : HTTP/1.1在请求头中加入了`Host`字段

### GET 和 POST 区别

- **GET**：**GET 的语义是从服务器获取指定的资源**，这个资源可以是静态的文本、页面、图片视频等。**GET 请求的参数位置一般是写在 URL 中**，URL 规定只能支持 ASCII，所以 GET 请求的参数只允许 ASCII 字符 ，而且浏览器会对 URL 的长度有限制（HTTP协议本身对 URL长度并没有做任何规定）
- **POST**：**POST 的语义是根据请求负荷（报文body）对指定的资源做出处理**，具体的处理方式视资源类型而不同。**POST 请求携带数据的位置一般是写在报文 body 中**， body 中的数据可以是任意格式的数据，只要客户端与服务端协商好即可，而且浏览器不会对 body 大小做限制

### HTTP 是不保存状态的协议, 如何保存用户状态

使用 Session 和 Cookie 机制

> cookie 被禁用 可以采用 URL 重写把 Session ID 直接附加在 URL 路径的后面

### HTTP 状态码

- **1XX（信息性状态码）**：接受的请求正在处理
- **2XX（成功状态码）**：请求正常处理完毕
- **3XX（重定向状态码）**：需要执行附加操作，301 永久重定向、302 临时重定向
- **4XX（客户端错误状态码）**：服务器无法处理请求， 401 请求要求身份认证、403(forbidden) 服务端拒绝执行请求、404 请求的资源不存在
- **5XX（服务器错误状态码）**：服务器处理请求出错， 500 服务器内部错误、501 服务器不支持请求功能、502 网关处理请求出错、503 超载或系统维护无法处理请求、504 网关超时

### URI 和 URL 区别

- **URI（Uniform Resource Identifier）**是统一资源标志符，可以唯一标识一个资源
- **URL（Uniform Resource Locator）**是统一资源定位符，可以提供该资源的路径。它是一种具体的 URI，即 URL 可以用来标识一个资源，而且还指明了如何 locate 这个资源

>  URI 的作用像身份证号一样，URL 的作用更像家庭住址一样。URL 是一种具体的 URI，它不仅唯一标识资源，而且还提供了定位该资源的信息。

## IP

### ICMP

ICMP 全称是 **Internet Control Message Protocol**，也就是**互联网控制报文协议**。`ICMP` 主要的功能包括：**确认 IP 包是否成功送达目标地址、报告发送过程中 IP 包被废弃的原因和改善网络设置等**。

ICMP 包头的**类型**字段，大致可以分为两大类：

- 一类是用于诊断的查询消息，也就是「**查询报文类型**」。主要有会送请求和会送响应

- 另一类是通知出错原因的错误消息，也就是「**差错报文类型**」。主要有目标不可达消息 、原点抑制消息 、重定向消息 、超时消息 —— 类型 `11`

> ping 的原理是 ICMP 中查询报文

### ARP

主机 A 向主机 B 通信的过程

1. A主机在自己的本地ARP缓存中检查主机B的匹配MAC地址
2. 若主机A在ARP缓存中没有找到映射，它会将ARP请求帧广播到本地网络上的所有主机。源主机A的IP地址和MAC地址都包括在ARP请求中。本地网络上的每台主机都接收到ARP请求并且检查是否与自己的IP地址匹配。如果主机发现请求的IP地址与自己的IP地址不匹配，它将丢弃ARP请求
3. 主机B确定ARP请求中的IP地址与自己的IP地址匹配，则将主机A的IP地址和MAC地址 [映射](http://baike.baidu.com/view/21249.htm)添加到本地ARP缓存中
4. 主机B将包含其MAC地址的ARP回复消息直接发送回主机A
5. 当主机A收到从主机B发来的ARP回复消息时，会用主机B的IP和MAC地址映射更新ARP缓存。本机缓存是有 [生存期](http://baike.baidu.com/view/159877.htm)的，生存期结束后，将再次重复上面的过程。主机B的MAC地址一旦确定，主机A就能向主机B发送IP通信了

# 数据库

## 数据库基础

### 数据库设计步骤

1. 需求分析
2. 概念设计（设计 ER 图）
3. 逻辑设计（ER 图 -> 表）
4. 物理设计（选择合适的存储结构和存取路径）
5. 数据库实施
6. 数据库运行和维护

### 主键和外键

- **主键(主码)** ：主键用于唯一标识一个元组，不能有重复，不允许为空。一个表只能有一个主键

- **外键(外码)** ：外键用来和其他表建立联系用，外键是另一表的主键，外键是可以有重复的，可以是空值。一个表可以有多个外键

  > **不推荐使用外键，外键概念在应用层解决**。原因：增加复杂性（DELETE 或者UPDATE都必须考虑外键约束）、增加额外工作（维护外键）、对分库分表不友好

### ER 图

实体-联系图(Entity Relationship Diagram)，提供了表示实体类型、属性和联系的方法，用来描述现实世界的**概念模型**。 

### 数据库范式

- **第一范式**：属性不可分
- **第二范式**：在第一范式的基础上，消除了非主属性对于码的部分函数依赖
- **第三范式**：在第二范式的基础上，消除了非主属性对于码的传递函数依赖 

### 存储过程

存储过程看成是一些 SQL 语句的集合，中间加了点逻辑控制语句。使用存储过程比单纯 SQL 语句执行要快，因为存储过程是预编译过的。

> 存储过程在互联网公司应用不多，因为存储过程难以调试和扩展，而且没有移植性，还会消耗数据库资源

## Mysql

### 存储引擎

**MyISAM 和 InnoDB 的区别**

|                                        | MyISAM                 | InnoDB                                                       |
| -------------------------------------- | ---------------------- | ------------------------------------------------------------ |
| **是否支持事务**                       | 不支持                 | 支持                                                         |
| **是否支持行级锁**                     | 不支持                 | 支持                                                         |
| **是否支持外键**                       | 不支持                 | 支持                                                         |
| **是否支持数据库异常崩溃后的安全恢复** | 不支持                 | 支持                                                         |
| **索引实现**（都是B+ Tree）            | 索引文件和数据文件分离 | 数据文件本身就是按 B+Tree 组织的一个索引结构，树的叶节点 data 域保存了完整的数据记录 |

> 存储引擎是基于表的。Mysql 默认存储引擎是 InnoDB。大部分情况下我们也选择 InnoDB

### 索引

**索引的优缺点**

优点：

- 使用索引可以大大**加快数据的检索速度**
- 通过创建唯一性索引，可以保证数据库表中每一行数据的**唯一性**

缺点：

- **创建索引和维护索引需要耗费许多时间**。当对表中的数据进行增删改的时候，如果数据有索引，那么索引也需要动态的修改，会**降低 SQL 执行效率**
- 索引需要使用物理空间存储，也会**耗费一定空间**

**索引的底层数据结构**

- **Hash 索引**：采用 Hash 算法，查询复杂度 O(1) 。但是 Hash 索引不支持顺序和范围查询

- **B Tree 和 B+ Tree 索引**：多路平衡查找树。大部分数据库系统及文件系统都采用 B-Tree 或其变种 B+Tree 作为索引结构

  | B Tree                                                       | B+ Tree                                                      |
  | ------------------------------------------------------------ | ------------------------------------------------------------ |
  | 所有节点既存放键（key） 也存放数据（data）                   | 只有叶子节点存放 key 和 data，其他内节点只存放 key           |
  | 叶子节点都是独立的                                           | 叶子节点有一条引用链指向与它相邻的叶子节点                   |
  | B 树的检索的过程相当于对范围内的每个节点的关键字做二分查找，可能还没有到达叶子节点，检索就结束了 | B+ 树的检索**效率就很稳定了**，任何查找都是从根节点到叶子节点的过程，叶子节点的顺序检索很明显 |

**聚簇索引与非聚簇索引**

- **聚簇索引**：**索引结构和数据一起存放**的索引，并不是一种单独的索引类型。InnoDB 中的主键索引就属于聚簇索引
- **非聚簇索引**：**索引结构和数据分开存放**的索引，并不是一种单独的索引类型。二级索引（辅助索引）就属于非聚簇索引

> 非聚簇索引不一定需要回表查询。当查询的字段正好建立了索引，就不需要回表查询。

**覆盖索引**

覆盖索引即**需要查询的字段正好是索引的字段**，那么直接根据该索引，就可以查到数据了，而**无需回表查询**

**联合索引**

使用表中的多个字段创建索引，就是 **联合索引**

**最左前缀匹配原则**

在使用联合索引时，**MySQL** 会根据联合索引中的字段顺序，从左到右依次到查询条件中去匹配，如果**查询条件中存在与联合索引中最左侧字段相匹配的字段，索引才会生效**

> 解释：当创建（a,b,c）联合索引时，想要索引生效的话，只能使用 a 和 ab、ac 和 abc 三种组合

**在哪些字段常建立索引**

- **不为 NULL 的字段** ：索引字段的数据应该尽量不为 NULL，因为对于数据为 NULL 的字段，数据库较难优化。如果字段频繁被查询，但又避免不了为 NULL，建议使用 0,1,true,false 这样语义较为清晰的短值或短字符作为替代。
- **被频繁查询的字段** ：我们创建索引的字段应该是查询操作非常频繁的字段。
- **被作为条件查询的字段** ：被作为 WHERE 条件查询的字段，应该被考虑建立索引。
- **频繁需要排序的字段** ：索引已经排序，这样查询可以利用索引的排序，加快排序查询时间。
- **被经常频繁用于连接的字段** ：经常用于连接的字段可能是一些外键列，对于外键列并不一定要建立外键，只是说该列涉及到表与表的关系。对于频繁被连接查询的字段，可以考虑建立索引，提高多表连接查询的效率

**使用索引注意事项**

- 被频繁更新的字段应该慎重建立索引
- 尽可能的考虑建立联合索引而不是单列索引
- 注意避免冗余索引

**索引失效场景**

- 使用 `SELECT *` 进行查询
- 创建了组合索引，但查询条件未准守最左匹配原则
- 在索引列上进行计算、函数、类型转换等操作
- 以 % 开头的 LIKE 查询比如 `like '%abc'`
- 查询条件中使用 or，且 or 的前后条件中有一个列没有索引，涉及的索引都不会被使用到

### 事务

**事务概念**

事务是**逻辑上的一组操作**，要么都执行，要么都不执行

**事务的 ACID 特性**

- **原子性**（`Atomicity`） ： 事务是最小的执行单位，不允许分割。事务的原子性确保动作要么全部完成，要么完全不起作用

- **一致性**（`Consistency`）： **执行事务前后，数据保持一致**。例如转账业务中，无论事务是否成功，转账者和收款人的总额应该是不变的

- **隔离性**（`Isolation`）： **并发访问数据库**时，一个用户的事务不被其他事务所干扰，各并发事务之间数据库是独立的

- **持久性**（`Durability`）： 一个事务被提交之后。它对数据库中数据的改变是持久的，即使数据库发生故障也不应该对其有任何影响

  > **只有保证了事务的持久性、原子性、隔离性之后，一致性才能得到保障。也就是说 A、I、D 是手段，C 是目的**

**并发事务带来的问题**

- **脏读**：一个事务读取数据并且对数据进行了修改，这个修改对其他事务来说是可见的，即使**当前事务没有提交。这时另外一个事务读取了这个还未提交的数据，但第一个事务突然回滚，导致数据并没有被提交到数据库，那第二个事务读取到的就是脏数据**

  > 在修改时加排他锁，直到事务提交才释放。 读取时加共享锁，读完释放锁。

- **丢失修改**：在一个事务读取一个数据时，另外一个事务也访问了该数据，那么**在第一个事务中修改了这个数据后，第二个事务也修改了这个数据。这样第一个事务内的修改结果就被丢失**

- **不可重复读**：**一个事务内多次读同一数据**。在这个事务还没有结束时，另一个事务也访问该数据。那么，**在第一个事务中的两次读数据之间，由于第二个事务的修改导致第一个事务两次读取的数据可能不太一样**

  > 

- **幻读**：幻读与不可重复读类似。它发生在一个事务读取了几行数据，接着**另一个并发事务插入了一些数据时。在随后的查询中，第一个事务就会发现多了一些原本不存在的记录**，就好像发生了幻觉一样

  > 不可重复读的重点是内容修改或者记录减少比如多次读取一条记录发现其中某些记录的值被修改。幻读的重点在于记录新增比如多次执行同一条查询语句（DQL）时，发现查到的记录增加了
  >
  > 幻读其实可以看作是不可重复读的一种特殊情况，单独把区分幻读的原因主要是解决幻读和不可重复读的方案不一样：
  >
  > 执行 `delete` 和 `update` 操作的时候，可以直接对记录加锁，保证事务安全。而执行 `insert` 操作的时候，由于记录锁（Record Lock）只能锁住已经存在的记录，为了避免插入新记录，需要依赖间隙锁（Gap Lock）

**SQL 标准定义了哪些事务隔离级别**

- **READ-UNCOMMITTED(读取未提交)** ： 最低的隔离级别，允许读取尚未提交的数据变更，可能会导致脏读、幻读或不可重复读。
- **READ-COMMITTED(读取已提交)** ： 允许读取并发事务已经提交的数据，可以阻止脏读，但是幻读或不可重复读仍有可能发生。
- **REPEATABLE-READ(可重复读)** ： 对同一字段的多次读取结果都是一致的，除非数据是被本身事务自己所修改，可以阻止脏读和不可重复读，但幻读仍有可能发生。
- **SERIALIZABLE(可串行化)** ： 最高的隔离级别，完全服从 ACID 的隔离级别。所有的事务依次逐个执行，这样事务之间就完全不可能产生干扰，也就是说，该级别可以防止脏读、不可重复读以及幻读。

**Mysql 默认隔离级别**

 InnoDB 存储引擎的默认支持的隔离级别是 **REPEATABLE-READ（可重读）**。是基于锁和 MVCC 机制共同实现的。

> SERIALIZABLE 隔离级别，是通过锁来实现的。除了 SERIALIZABLE 隔离级别，其他的隔离级别都是基于 MVCC 实现。
>
> 不过， SERIALIZABLE 之外的其他隔离级别可能也需要用到锁机制，就比如 REPEATABLE-READ 在当前读情况下需要使用加锁读来保证不会出现幻读。

### 锁

**表级锁和行级锁**

- **表级锁**

  MySQL 中锁定粒度最大的一种锁（全局锁除外），是**针对非索引字段加的锁**，对当前操作的整张表加锁，实现简单，资源消耗也比较少，加锁快，不会出现死锁。其锁定粒度最大，触发锁冲突的概率最高，并发度最低，MyISAM 和 InnoDB 引擎都支持表级锁

  - **表锁**：整个表加上的锁
  - **意向锁**：需要用到表锁的话需要判断表中的记录没有行锁。一行一行遍历肯定是不行，性能太差。我们需要用到意向锁来**快速判断是否可以对某个表使用表锁**。意向锁是有数据引擎自己维护的，用户无法手动操作意向锁，在为数据行加共享 / 排他锁之前，InooDB 会先获取该数据行所在在数据表的对应意向锁

- **行级锁**

  MySQL 中锁定粒度最小的一种锁，是**针对索引字段加的锁**，只针对当前操作的行记录进行加锁。 行级锁能大大减少数据库操作的冲突。其加锁粒度最小，并发度高，但加锁的开销也最大，加锁慢，会出现死锁

  - **行锁**：单个行记录上的锁
  - **间隙锁**：锁定一个范围，不包括记录本身
  - **临键锁**（**Next-Key Lock**）：行锁 + 间隙锁。锁定一个范围，包含记录本身。主要目的是为了**解决幻读问题（MySQL 事务部分提到过）**。记录锁只能锁住已经存在的记录，为了避免插入新记录，需要依赖间隙锁

**共享锁和排他锁**

不论是表级锁还是行级锁，都存在共享锁（Share Lock，S 锁）和排他锁（Exclusive Lock，X 锁）这两类：

- **共享锁（S 锁）** ：又称读锁，事务在读取记录的时候获取共享锁，允许多个事务同时获取（锁兼容）。
- **排他锁（X 锁）** ：又称写锁/独占锁，事务在修改记录的时候获取排他锁，不允许多个事务同时获取。如果一个记录已经被加了排他锁，那其他事务不能再对这条事务加任何类型的锁（锁不兼容）。

>  排他锁与任何的锁都不兼容，共享锁仅和共享锁兼容

**当前读和快照读**

- **当前读**（一致性锁定读）：读取的是**记录的最新版本**，读取时还要保证其他并发事务不能修改当前记录，会对读取的记录进行**加锁**

  > SELECT ... FOR UPDATE
  > SELECT ... LOCK IN SHARE MODE

- **快照读**（一致性非锁定读）：读到的并不一定是数据的最新版本，而有可能是之前的历史版本

  > 之所以出现快照读的情况，是基于提高并发性能的考虑，快照读的实现是基于多版本并发控制，即MVCC,可以认为MVCC是行锁的一个变种，但它**在很多情况下，避免了加锁操作，降低了开销**

**隔离级别 RR（可重复读）解决幻读问题**

> 幻读的原因归根到底是**由于查询得到的结果与真实的结果不匹配**。 幻读重点在于数据是否存在 。 原本不存在的数据却真实的存在了，这便是幻读

分为两种情况

- **快照读** ：由 MVCC 机制来保证不出现幻读
- **当前读** ： 使用 Next-Key Lock 进行加锁来保证不出现幻读

RR 并不能完全解决幻读问题，2个例子

第一个例子：对于快照读， MVCC 并不能完全避免幻读现象。因为当事务 A 更新了一条事务 B 插入的记录，那么事务 A 前后两次查询的记录条目就不一样了，所以就发生幻读。

第二个例子：对于当前读，如果事务开启后，并没有执行当前读，而是先快照读，然后这期间如果其他事务插入了一条记录，那么事务后续使用当前读进行查询的时候，就会发现两次查询的记录条目就不一样了，所以就发生幻读。

**redo log 和 undo log**

- **redo log**

redo log（重做日志）是 InnoDB 存储引擎独有的，它让 MySQL 拥有了崩溃恢复能力

比如 MySQL 实例挂了或宕机了，重启时，**InnoDB 存储引擎会使用 redo log 恢复数据，保证数据的持久性与完整性**

- **undo log**

**想要保证事务的原子性，就需要在异常发生时，对已经执行的操作进行回滚。在 MySQL 中，恢复机制是通过回滚日志（undo log）实现的**。所有事务进行的修改都会先记录到这个回滚日志中，然后再执行相关的操作。如果执行过程中遇到异常的话，我们直接利用回滚日志中的信息将数据回滚到修改之前的样子即可！

**回滚日志会先于数据持久化到磁盘上**。这样就保证了即使遇到数据库突然宕机等情况，当用户再次启动数据库的时候，数据库还能够通过查询回滚日志来回滚将之前未完成的事务

### MVCC



### SQL

**sql 优化**

- **尽量避免使用子查询（用 Inner join）** 
- **连接查询，小表驱动大表**
- **用 IN 来替换 OR**
- **读取适当的记录LIMIT M,N，而不要读多余的记录**
- **只返回必要的列，用具体的字段列表代替 select \* 语句**
- **经常使用的查询可以开启缓存**

**sql 语句在 Mysql 的执行过程**

![img](https://guide-blog-images.oss-cn-shenzhen.aliyuncs.com/javaguide/13526879-3037b144ed09eb88.png)

**查询语句**

1. 先检查该语句是否有权限，如果没有权限，直接返回错误信息，如果有权限，在 MySQL8.0 版本以前，会先查询缓存，以这条 SQL 语句为 key 在内存中查询是否有结果，如果有缓存命中，直接返回；如果没有，执行下一步。

2. 通过分析器进行词法分析，提取 SQL 语句的关键元素，比如提取上面这个语句是查询 select，提取需要查询的表名为 tb_student，需要查询所有的列，查询条件是这个表的 id='1'。然后判断这个 SQL 语句是否有语法错误，比如关键词是否正确等等，如果检查没问题就执行下一步。

3. 接下来就是优化器进行确定执行方案，上面的 SQL 语句，可以有两种执行方案：

4. ```
     a.先查询学生表中姓名为“张三”的学生，然后判断是否年龄是 18。
     b.先找出学生中年龄 18 岁的学生，然后再查询姓名为“张三”的学生。
   ```

5. 那么优化器根据自己的优化算法进行选择执行效率最好的一个方案（优化器认为，有时候不一定最好）。那么确认了执行计划后就准备开始执行了。

6. 进行权限校验，如果没有权限就会返回错误信息，如果有权限就会调用数据库引擎接口，返回引擎的执行结果

**更新语句**

```sql
b_student A set A.age='19' where A.name=' 张三 ';
```

1. 先查询到张三这一条数据，如果有缓存，也是会用到缓存。

2. 然后拿到查询的语句，把 age 改为 19，然后调用引擎 API 接口，写入这一行数据，InnoDB 引擎把数据保存在内存中，同时记录 redo log，此时 redo log 进入 prepare 状态，然后告诉执行器，执行完成了，随时可以提交。

3. 执行器收到通知后记录 binlog，然后调用引擎接口，提交 redo log 为提交状态。

   > 这里 redo log 采用了两阶段式的提交，可以保证数据的一致性

4. 更新完成。

**自增ID与UUID的比较**

- 自增ID是有序的，而UUID是随机的。如果主键是有序的，数据库可以具有更好的性能（至少对MySQL而已是如此）
  自增ID所需的存储空间比UUID要小

- 由于自增ID比UUID更加简单，因此生成自增ID的生成速度也比UUID更快

- 自增ID与数据相关，主键会暴露出去的话，自增ID会显示当前表中的数据规模；而UUID则无此风险

- 自增ID在不同的数据库中可能重复，在分布式的环境下无法保证唯一。而UUID在分布式环境下也可以保证唯一

  **具体而已，自增ID在性能上更有优势，而UUID则更加适应分布式场景**

## Redis

### 基础

#### Redis 为什么这么快

- Redis 基于**内存**，内存的访问速度是磁盘的上千倍
- Redis 基于 Reactor 模式设计开发了一套高效的事件处理模型，主要是**单线程事件循环**和** IO 多路复用**
- Redis 内置了多种**优化过后的数据结构实现**，性能非常高

#### 为什么使用Redis

- **高性能**：如果用户访问的数据属于高频数据并且**不会经常改变**的话，那么我们就可以很放心地将该用户访问的数据存在缓存中。那就保证用户下一次再访问这些数据的时候就可以直接从缓存中获取了。操作缓存就是直接操作内存，所以速度相当快
- **高并发**：一般像 MySQL 这类的数据库的 QPS 大概都在 1w 左右（4 核 8g） ，但是使用 Redis 缓存之后很容易达到 10w+，甚至最高能达到 30w+

#### Redis 和 Memcached 的区别

- Redis 有更丰富的数据类型
- Redis 支持持久化
- Redis 支持灾难恢复机制
- redis 支持集群

### 数据结构

- **5 种基础数据结构** ：
  - String（字符串）：需要存储**常规数据**的场景、需要**计数**的场景
  - List（列表）：**信息流展示**（最新文章、最新动态）
  - Set（集合）：需要存放的数据**不能重复**的场景、需要获取多个数据源**交集、并集和差集**的场景**、**需要**随机**获取数据源中的元素的场景
  - Hash（散列）：**对象数据存储场景**
  - Zset（有序集合）：需要**随机获取数据源中的元素根据某个权重进行排序**的场景
- **3 种特殊数据结构** ：HyperLogLogs（基数统计）、Bitmap （位存储）、Geospatial (地理位置)

#### List 底层数据结构

#### Zset 底层数据结构

主要有跳表和压缩列表

**跳表**



### 线程模型

对于读写命令来说，Redis 一直是单线程模型

**Redis 基于 Reactor 模式设计开发了一套高效的事件处理模型** ，这套事件处理模型对应的是 Redis 中的文件事件处理器（file event handler）。由于文件事件处理器（file event handler）是单线程方式运行的，所以我们一般都说 Redis 是单线程模型

Redis 通过 **IO 多路复用程序** 来监听来自客户端的大量连接（或者说是监听多个 socket），它会将感兴趣的事件及类型（读、写）注册到内核中并监听每个事件是否发生

#### 为什么不适用多线程

- 单线程编程容易并且更容易维护
- Redis 的性能瓶颈不在 CPU ，主要在内存和网络
- 多线程就会存在死锁、线程上下文切换等问题，甚至会影响性能

#### Redis6.0 后为什么又引入了多线程

Redis6.0 引入多线程主要是为了**提高网络 IO 读写性能**，因为这个算是 Redis 中的一个性能瓶颈

### 内存管理

#### 为什么设置键的过期时间

内存是有限的，如果缓存中的所有数据都是一直保存的话 很容易 Out of memory。

很多时候，我们的业务场景就是需要某个数据只在某一时间段内存在，比如我们的短信验证码可能只在 1 分钟内有效，用户登录的 token 可能只在 1 天内有效。如果使用传统的数据库来处理的话，一般都是自己判断过期，这样更麻烦并且性能要差很多。

#### 如何判断数据是否过期

通过过期字典

#### 过期的数据的删除策略

**惰性删除** ：只会在取出 key 的时候才对数据进行过期检查。这样对 CPU 最友好，但是可能会造成太多过期 key 没有被删除。

**定期删除** ： 每隔一段时间抽取一批 key 执行删除过期 key 操作。并且，Redis 底层会通过限制删除操作执行的时长和频率来减少删除操作对 CPU 时间的影响

定期删除对内存更加友好，惰性删除对 CPU 更加友好。两者各有千秋，所以 Redis 采用的是 **定期删除+惰性/懒汉式删除** 

#### 内存淘汰机制

- **noeviction**：默认禁止驱逐数据。内存不够使用时，对申请内存的命令报错。
- **volatile-lru（least recently used）**：从**已设置过期时间的数据集**（server.db[i].expires）中挑选**最近最少使用**的数据淘汰
- **volatile-ttl**：从已设置过期时间的数据集（server.db[i].expires）中挑选**将要过期**的数据淘汰
- **volatile-random**：从已设置过期时间的数据集（server.db[i].expires）中**任意选择数据**淘汰
- **allkeys-lru（least recently used）**：当内存不足以容纳新写入数据时，在所有键空间中，移除**最近最少使用的 key**（这个是最常用的）
- **allkeys-random**：从所有键空间（server.db[i].dict）中**任意选择数据**淘汰

### 持久化

#### RDB**（snapshotting）**持久化

通过**创建快照来获得存储在内存里面的数据在某个时间点上的副本**。Redis 创建快照之后，可以**对快照进行备份**，可以将快照复制到其他服务器从而创建具有相同数据的服务器副本（Redis 主从结构，主要用来提高 Redis 性能），还可以将快照留在原地以便重启服务器的时候使用

使用 bgsave 命令 RDB 存储过程如下：

1、用户执行bgsave命令触发RDB存储。
2、redis主进程先检查当前是否有子进程，如果当前有子进程将不会执行本次操作。如果没有子进程，创建子进程。
3、子进程执行RDB存储，主进程响应用户请求。
4、子进程拷贝xx.rdb到一个临时文件中。
5、子进程将新增的数据写入到xx.rdb的临时文件中。
6、子进程将xx.rdb的临时文件覆盖原来的xx.rdb文件 

#### AOF（append only file）持久化

与快照持久化相比，AOF 持久化的实时性更好，已成为主流的持久化方案

开启 AOF 持久化后每执行一条会更改 Redis 中的数据的命令，Redis 就会**将该命令写入到内存缓存** `server.aof_buf` 中，然后根据配置文件中的策略向硬盘的xx.aof文件中追加命令

**三种不同的 AOF 方式**

- **appendfsync always**：每次有数据修改发生时都会写入AOF文件,这样会严重降低Redis的速度
- **appendfsync everysec**：每秒钟同步一次，显式地将多个写命令同步到硬盘 
- **appendfsync no**：让操作系统决定何时进行同步

为了兼顾数据和写入性能，用户可以考虑 `appendfsync everysec` 选项 ，让 Redis 每秒同步一次 AOF 文件，Redis 性能几乎没受到任何影响。而且这样即使出现系统崩溃，用户最多只会丢失一秒之内产生的数据

#### 如何选择 RDB 和 AOF

**RDB 比 AOF 优秀的地方**

- RDB 文件存储的内容是经过压缩的二进制数据， 保存着某个时间点的数据集，**文件很小**，适合做数据的备份、灾难恢复。AOF 文件存储的是每一次写命令，类似于 MySQL 的 binlog 日志，通常会比 RDB 文件大很多。当 AOF 变得太大时，Redis 能够在后台自动重写 AOF。新的 AOF 文件和原有的 AOF 文件所保存的数据库状态一样，但体积更小
- 使用 RDB 文件恢复数据，**直接解析还原数据**即可，不需要一条一条地执行命令，速度非常快。而 AOF 则需要依次执行每个写命令，速度非常慢

**AOF 比 RDB 优秀的地方**

- RDB 的**数据安全性**不如 AOF，没有办法实时或者秒级持久化数据
- AOF 以一种易于理解和解析的格式包含所有操作的日志。你可以轻松地导出 AOF 文件进行分析，你也可以直接操作 AOF 文件来解决一些问题

### 事务

#### Redis 支持原子性吗

Redis 事务在运行错误的情况下，除了执行过程中出现错误的命令外，其他命令都能正常执行。并且，Redis 是**不支持回滚（roll back）操作**的。因此，Redis 事务其实是不满足原子性的（而且不满足持久性）

Redis 官网也解释了自己为啥不支持回滚。简单来说就是 Redis 开发者们觉得没必要支持回滚，这样更简单便捷并且性能更好。Redis 开发者觉得即使**命令执行错误也应该在开发过程中就被发现而不是生产过程中**

### 生产问题

#### 缓存穿透

缓存穿透说简单点就是**大量请求的 key 是不合理的，根本不存在于缓存中，也不存在于数据库中** 。这就导致这些请求直接到了数据库上，根本没有经过缓存这一层，对数据库造成了巨大的压力，可能直接就被这么多请求弄宕机了

**解决方法**

最基本的就是首先**做好参数校验**，一些不合法的参数请求直接抛出异常信息返回给客户端。比如查询的数据库 id 不能小于 0、传入的邮箱格式不对的时候直接返回错误消息给客户端等等

- **缓存无效 key**
- **布隆过滤器**。布隆过滤器是一个非常神奇的数据结构，通过它我们**可以非常方便地判断一个给定数据是否存在于海量数据中**。**把所有可能存在的请求的值都存放在布隆过滤器中**，当用户请求过来，先判断用户发来的请求的值是否存在于布隆过滤器中。不存在的话，直接返回请求参数错误信息给客户端，存在的话才会走下面的流程

> 布隆过滤器可能会存在误判的情况。总结来说就是： **布隆过滤器说某个元素存在，小概率会误判(hash 相同的原因)。布隆过滤器说某个元素不在，那么这个元素一定不在**

#### 缓存击穿

缓存击穿中，请求的 key 对应的是 **热点数据** ，该数据 **存在于数据库中，但不存在于缓存中（通常是因为缓存中的那份数据已经过期）** 。这就可能会导致瞬时大量的请求直接打到了数据库上，对数据库造成了巨大的压力，可能直接就被这么多请求弄宕机了

**解决方法**

- **设置热点数据永不过期或者过期时间比较长**
- **针对热点数据提前预热**，将其存入缓存中并设置合理的过期时间比如秒杀场景下的数据在秒杀结束之前不过期
- **请求数据库写数据到缓存之前，先获取互斥锁**，保证只有一个请求会落到数据库上，减少数据库的压力

#### 缓存穿透和缓存击穿有什么区别

缓存穿透中，请求的 key 既不存在于缓存中，也不存在于数据库中。

缓存击穿中，请求的 key 对应的是 **热点数据** ，该数据 **存在于数据库中，但不存在于缓存中（通常是因为缓存中的那份数据已经过期）** 

#### 缓存雪崩

缓存**在同一时间大面积的失效（大量数据在同一时间过期）**，导致大量的请求都直接落到了数据库上，对数据库造成了巨大的压力。缓存服务宕机也会导致缓存雪崩现象，导致所有的请求都落到了数据库上

**解决方法**

**针对 Redis 服务不可用的情况：**

- 采用 **Redis 集群**，避免单机出现问题整个缓存服务都没办法使用
- **限流**，避免同时处理大量的请求

**针对热点缓存失效的情况：**

- 设置不同的失效时间比如随机设置缓存的失效时间

#### 缓存雪崩和缓存击穿有什么区别

缓存雪崩和缓存击穿比较像，但缓存雪崩导致的原因是**缓存中的大量或者所有数据失效**，缓存击穿导致的原因主要是**某个热点数据不存在于缓存中（通常是因为缓存中的那份数据已经过期）**

### 缓存和数据库数据的一致性问题

一个策略是**Cache Aside Pattern（旁路缓存模式）**。Cache Aside Pattern 中遇到写请求是这样的：**更新 DB，然后直接删除 cache** 。如果更新数据库成功，而删除缓存这一步失败的情况的话，如果 cache 服务当前不可用导致缓存删除失败的话，我们就隔一段时间进行重试，重试次数可以自己定。如果多次重试还是失败的话，我们可以把当前更新失败的 key 存入队列中，等缓存服务可用之后，再将缓存中对应的 key 删除即可。

缓存和数据库的数据不一致一般是由两个原因导致的  

-  删除缓存值或更新数据库失败而导致数据不一致，可以使用**重试**机制确保删除或更新操作成功。   

- 在删除缓存值、更新数据库的这两步操作中，有其他线程的并发读操作，导致其他线程读取到旧值，应对方案是**延迟双删**。   

  在大多数业务场景下，我们会把 Redis 作为只读缓存使用。针对只读缓存来说，我们既可以先删除缓存值再更新数据库，也可以先更新数据库再删除缓存。建议是，优先使用先更新数据库再删除缓存的方法，原因主要有两个：

  - 先写数据库再删缓存的线程安全问题更低
  
  - 先删除缓存值再更新数据库，有可能**导致请求因缓存缺失而访问数据库**，给数据库带来压力
  - 如果业务应用中读取数据库和写缓存的时间不好估算，那么，延迟双删中的等待时间就不好设置

### 分布式锁

Redis **本身可以被多个客户端共享访问**，正好就是一个共享存储系统，可以用来保存分布式锁，而且 Redis 的**读写性能高**，可以应对高并发的锁操作场景。

Redis 的 SET 命令有个 NX 参数可以实现「key不存在才插入」，所以可以用它来实现分布式锁：

- 如果 key 不存在，则显示插入成功，可以用来表示加锁成功；
- 如果 key 存在，则会显示插入失败，可以用来表示加锁失败。

基于 Redis 节点实现分布式锁时，对于加锁操作，我们需要满足三个条件。

- 加锁包括了**读取锁变量、检查锁变量值和设置锁变量值**三个操作，但需要以原子操作的方式完成，所以，我们使用 SET 命令带上 NX 选项来实现加锁；
- 锁变量需要**设置过期时间**，以免客户端拿到锁后发生异常，导致锁一直无法释放，所以，我们在 SET 命令执行时加上 EX/PX 选项，设置其过期时间；
- 锁变量的值需要能区分来自不同客户端的加锁操作，以免在释放锁时，出现误释放操作，所以，我们使用 SET 命令设置锁变量值时，**每个客户端设置的值是一个唯一值，用于标识客户端**；

```lua
SET lock_key unique_value NX PX 10000 
```

- lock_key 就是 key 键；
- unique_value 是客户端生成的唯一的标识，区分来自不同客户端的锁操作；
- NX 代表只在 lock_key 不存在时，才对 lock_key 进行设置操作；
- PX 10000 表示设置 lock_key 的过期时间为 10s，这是为了避免客户端发生异常而无法释放锁

而解锁的过程就是将 lock_key 键删除（del lock_key），但不能乱删，要保证执行操作的客户端就是加锁的客户端。所以，解锁的时候，我们要先判断锁的 unique_value 是否为加锁客户端，是的话，才将 lock_key 键删除。

可以看到，**解锁**是有两个操作，这时就需要 Lua 脚本来保证解锁的原子性。

**Redis 实现分布式锁的问题**

- 超时时间不好设置

- Redis 主从复制模式中的数据是异步复制的，这样导致分布式锁的不可靠性

  > 可以用 红锁 解决。Redlock 算法的基本思路，**是让客户端和多个独立的 Redis 节点依次请求申请加锁，如果客户端能够和半数以上的节点成功地完成加锁操作，那么我们就认为，客户端成功地获得分布式锁，否则加锁失败**。

### 分布式缓存

#### 主从复制

可以保证多台服务器的数据一致性，且主从服务器之间采用的是「读写分离」的方式。

主服务器可以进行读写操作，当发生写操作时自动将写操作同步给从服务器，而从服务器一般是只读，并接受主服务器同步过来写操作命令，然后执行这条命令。

![图片](https://img-blog.csdnimg.cn/img_convert/2b7231b6aabb9a9a2e2390ab3a280b2d.png)

主从服务器第一次同步的时候，采用**全量复制**，此时主服务器会两个耗时的地方，分别是生成 RDB 文件和传输 **RDB 文件**。为了避免过多的从服务器和主服务器进行全量复制，可以把一部分从服务器升级为**「经理角色」**，让它也有自己的从服务器，通过这样可以分摊主服务器的压力。

第一次同步完成后，主从服务器都会维护着一个**长连接**，主服务器在接收到**写操作命令后**，就会通过这个连接将写命令传播给从服务器，来保证主从服务器的数据一致性。

如果遇到网络断开，采用**增量复制**。

> 主从服务器之间的命令复制是**异步**进行的。主服务器并不会等到从服务器实际执行完命令后，再把结果返回给客户端，而是主服务器自己在本地执行完命令后，就会向客户端返回结果了。如果从服务器还没有执行主服务器同步过来的命令，主从服务器间的数据就不一致了

#### 哨兵

哨兵机制的作用是实现**主从节点故障转移**。它会监测主节点是否存活，如果发现主节点挂了，它就会选举一个从节点切换为主节点，并且把新主节点的相关信息通知给从节点和客户端。

哨兵一般是以**集群**的方式部署，至少需要 3 个哨兵节点，哨兵集群主要负责三件事情：**监控、选主、通知**。

#### 切片集群

将数据分布在不同的服务器上，以此来**降低系统对单主节点的依赖**，从而提高 Redis 服务的读写性能。

Redis Cluster 方案采用哈希槽（Hash Slot），来处理数据和节点之间的映射关系。在 Redis Cluster 方案中，哈希槽类似于数据分区，每个键值对都会根据它的 key，被映射到一个哈希槽中

哈希槽被映射到具体的 Redis 节点上，有两种方案：

- **平均分配：** 在使用 cluster create 命令创建 Redis 集群时，Redis 会自动把所有哈希槽平均分布到集群节点上。比如集群中有 9 个节点，则每个节点上槽的个数为 16384/9 个。
- **手动分配：** 可以使用 cluster meet 命令手动建立节点间的连接，组成集群，再使用 cluster addslots 命令，指定每个节点上的哈希槽个数。

## Spring

### 基础

#### Spring,Spring MVC,Spring Boot 之间什么关系

Spring 包含了多个功能模块（上面刚刚提到过），其中最重要的是 Spring-Core（主要提供 IoC 依赖注入功能的支持） 模块， Spring 中的其他模块（比如 Spring MVC）的功能实现基本都需要依赖于该模块

Spring MVC 是 Spring 中的一个很重要的模块，主要**赋予 Spring 快速构建 MVC 架构的 Web 程序的能力**。MVC 是模型(Model)、视图(View)、控制器(Controller)的简写，其核心思想是通过将业务逻辑、数据、显示分离来组织代码

使用 Spring 进行开发各种配置过于麻烦比如开启某些 Spring 特性时，需要用 XML 或 Java 进行显式配置。于是，Spring Boot 诞生了

**Spring 旨在简化 J2EE 企业应用程序开发。Spring Boot 旨在简化 Spring 开发（减少配置文件，开箱即用！）**。

> Spring Boot 只是简化了配置，如果你需要构建 MVC 架构的 Web 程序，你还是需要使用 Spring MVC 作为 MVC 框架，只是说 Spring Boot 帮你简化了 Spring MVC 的很多配置，真正做到开箱即用

### Spring IoC

#### 对 Spring IoC 的理解

IoC 的思想就是将原本在程序中手动创建对象的控制权，交由 Spring 框架来管理

- **控制** ：指的是对象创建（实例化、管理）的权力
- **反转** ：控制权交给外部环境（Spring 框架、IoC 容器）

将**对象之间的相互依赖关系交给 IoC 容器来管理，并由 IoC 容器完成对象的注入。这样可以很大程度上简化应用的开发，把应用从复杂的依赖关系中解放出来**。 IoC 容器就像是一个工厂一样，当我们需要创建一个对象的时候，只需要配置好配置文件/注解即可，完全不用考虑对象是如何被创建出来的

在 Spring 中， IoC 容器是 Spring 用来实现 IoC 的载体，**IoC 容器实际上就是个 Map（key，value），Map 中存放的是各种对象**

#### Spring Bean

简单来说，Bean 代指的就是那些**被 IoC 容器所管理的对象**。

我们需要告诉 IoC 容器帮助我们管理哪些对象，这个是通过配置元数据来定义的。配置元数据可以是 XML 文件、注解或者 Java 配置类

#### 将一个类声明为 Bean 的注解有哪些

- `@Component` ：通用的注解，可标注任意类为 `Spring` 组件。如果一个 Bean 不知道属于哪个层，可以使用`@Component` 注解标注。
- `@Repository` : 对应持久层即 Dao 层，主要用于数据库相关操作。
- `@Service` : 对应服务层，主要涉及一些复杂的逻辑，需要用到 Dao 层。
- `@Controller` : 对应 Spring MVC 控制层，主要用户接受用户请求并调用 Service 层返回数据给前端页面

#### @Component 和 @Bean 的区别是什么

- `@Component` 注解作用于**类**，而`@Bean`注解作用于**方法**。
- `@Component`通常是**通过类路径扫描来自动侦测以及自动装配到 Spring 容器中**（我们可以使用 `@ComponentScan` 注解定义要扫描的路径从中找出标识了需要装配的类自动装配到 Spring 的 bean 容器中）。`@Bean` 注解**通常是我们在标有该注解的方法中定义产生这个 bean,`@Bean`告诉了 Spring 这是某个类的实例，当我需要用它的时候还给我**。
- `@Bean` 注解比 `@Component` 注解的**自定义性更强，而且很多地方我们只能通过 `@Bean` 注解来注册 bean**。比如当我们引用第三方库中的类需要装配到 `Spring`容器时，则只能通过 `@Bean`来实现

#### 注入 Bean 的注解有哪些

Spring 内置的 `@Autowired` 以及 JDK 内置的 `@Resource` 和 `@Inject` 都可以用于注入 Bean

#### @Autowired 和 @Resource 的区别是什么

- `@Autowired` 是 Spring 提供的注解，`@Resource` 是 JDK 提供的注解。
- `Autowired` 默认的注入方式为`byType`（根据类型进行匹配），`@Resource`默认注入方式为 `byName`（根据名称进行匹配）。
- 当一个接口存在多个实现类的情况下，`@Autowired` 和`@Resource`都需要通过名称才能正确匹配到对应的 Bean。`Autowired` 可以通过 `@Qualifier` 注解来显式指定名称，`@Resource`可以通过 `name` 属性来显式指定名称

#### Bean 的作用域有哪些

- **singleton** : IoC 容器中只有唯一的 bean 实例。Spring 中的 bean 默认都是单例的，是对单例设计模式的应用。
- **prototype** : 每次获取都会创建一个新的 bean 实例。也就是说，连续 `getBean()` 两次，得到的是不同的 Bean 实例。
- **request** （仅 Web 应用可用）: 每一次 HTTP 请求都会产生一个新的 bean（请求 bean），该 bean 仅在当前 HTTP request 内有效。
- **session** （仅 Web 应用可用） : 每一次来自新 session 的 HTTP 请求都会产生一个新的 bean（会话 bean），该 bean 仅在当前 HTTP session 内有效。
- **application/global-session** （仅 Web 应用可用）： 每个 Web 应用在启动时创建一个 Bean（应用 Bean），该 bean 仅在当前应用启动时间内有效

#### 单例 Bean 的线程安全问题

单例 Bean 存在线程问题，主要是因为当多个线程操作同一个对象的时候是存在资源竞争的。

常见的有两种解决办法：

1. 在 Bean 中尽量避免定义可变的成员变量
2. 在类中定义一个 `ThreadLocal` 成员变量，将需要的可变成员变量保存在 `ThreadLocal` 中（推荐的一种方式）

不过，大部分 Bean 实际都是无状态（没有实例变量）的（比如 Dao、Service），这种情况下， Bean 是线程安全的

#### Bean 的生命周期

- Bean 容器**找到**配置文件中 Spring Bean 的**定义**
- **实例化**。Bean 容器利用 Java 反射 API **创建一个 Bean 的实例**
- **属性赋值**。如果涉及到一些属性值 利用 `set()`方法**设置一些属性值、依赖注入**
- **初始化**。各种方法调用。包括 Aware 接口方法，Bean 自身方法，生命周期接口方法，后处理器接口方法等
- **销毁**。当要销毁 Bean 的时候，如果 Bean 实现了 `DisposableBean` 接口，执行 `destroy()` 方法
- 当要销毁 Bean 的时候，如果 Bean 在配置文件中的定义包含 destroy-method 属性，执行指定的方法

![image-20230321151337847](/Users/dalang/Library/Application Support/typora-user-images/image-20230321151337847.png)

### Spring AOP

AOP(Aspect-Oriented Programming:面向切面编程)将那些与业务无关，却为业务模块所共同调用的代码（例如事务处理、日志管理、权限控制等）封装起来，便于减少系统的重复代码，降低模块间的耦合度，提升了代码的可拓展性和可维护性

Spring AOP 基于**动态代理**。如果要代理的对象，**实现了某个接口**，那么 Spring AOP 会使用 **JDK Proxy**，去创建代理对象；而对于没有实现接口的对象，这时候 Spring AOP 会使用 **Cglib** 生成一个被代理对象的子类来作为代理

#### Spring AOP 和 AspectJ AoP 有什么区别？

**Spring AOP 属于运行时增强，而 AspectJ 是编译时增强。** Spring AOP 基于代理(Proxying)，而 AspectJ 基于字节码操作(Bytecode Manipulation)。

如果我们的切面比较少，那么两者性能差异不大。但是，当切面太多的话，最好选择 AspectJ ，它比 Spring AOP 快很多。

#### AspectJ 定义的通知类型有哪些

- **Before**（前置通知）：目标对象的方法调用之前触发
- **After** （后置通知）：目标对象的方法调用之后触发
- **AfterReturning**（返回通知）：目标对象的方法调用完成，在返回结果值之后触发
- **AfterThrowing**（异常通知） ：目标对象的方法运行中抛出 / 触发异常后触发。AfterReturning 和 AfterThrowing 两者互斥。如果方法调用成功无异常，则会有返回值；如果方法抛出了异常，则不会有返回值。
- **Around** （环绕通知）：编程式控制目标对象的方法调用。**环绕通知是所有通知类型中可操作范围最大的一种，因为它可以直接拿到目标对象，以及要执行的方法**，所以环绕通知可以任意的在目标对象的方法调用前后进行处理，甚至不调用目标对象的方法

### Spring MVC

#### Spring MVC 工作原理

![img](https://img-blog.csdnimg.cn/img_convert/de6d2b213f112297298f3e223bf08f28.png)

**流程**：

1. 客户端（浏览器）发送请求， `DispatcherServlet`拦截请求。
2. `DispatcherServlet` 根据请求信息调用 `HandlerMapping` 。`HandlerMapping` **根据 uri 去匹配查找能处理的 `Handler`（也就是我们平常说的 `Controller` 控制器）** ，并会将请求涉及到的拦截器和 `Handler` 一起封装。
3. `DispatcherServlet` 调用 `HandlerAdapter`适配**执行 `Handler` **。
4. `Handler` 完成对用户请求的处理后，会返回一个 `ModelAndView` 对象给`DispatcherServlet`，`ModelAndView` 顾名思义，包含了数据模型以及相应的视图的信息。`Model` 是返回的数据对象，`View` 是个逻辑上的 `View`。
5. `ViewResolver` 会根据逻辑 `View` 查找实际的 `View`。
6. `DispaterServlet` 把返回的 `Model` 传给 `View`（视图渲染）。
7. 把 `View` 返回给请求者（浏览器）

### Spring 事务

#### Spring管理事务的方式

**编程式事务** ： 在代码中硬编码(不推荐使用) : 通过 `TransactionTemplate`或者 `TransactionManager` 手动管理事务，实际应用中很少使用，但是对于你理解 Spring 事务管理原理有帮助。

**声明式事务** ： 在 XML 配置文件中配置或者直接基于注解（推荐使用） : 实际是通过 AOP 实现（基于`@Transactional` 的全注解方式使用最多）

#### Spring事务有哪几种传播行为

**事务传播行为是解决方法之间互相调用的事务问题**

*正确的传播行为*

**1.`TransactionDefinition.PROPAGATION_REQUIRED`**

使用的最多的一个事务传播行为，我们平时经常使用的`@Transactional`注解默认使用就是这个事务传播行为。如果当前存在事务，则加入该事务；如果当前没有事务，则创建一个新的事务

**`2.TransactionDefinition.PROPAGATION_REQUIRES_NEW`**

创建一个新的事务，如果外部方法存在事务，则把外部方法的事务挂起。

**3.`TransactionDefinition.PROPAGATION_NESTED`**

如果当前存在事务，则创建一个事务作为当前事务的嵌套事务来运行；如果当前没有事务，则该取值等价于`TransactionDefinition.PROPAGATION_REQUIRED`。

**4.`TransactionDefinition.PROPAGATION_MANDATORY`**

如果当前存在事务，则加入该事务；如果当前没有事务，则抛出异常。

**错误的传播行为不会回滚**

#### 事务失效场景

- @Transaction 注解在非 public 的方法上
- 有 检查异常
- 异常被 catch
- @Transactional 注解的 rollbackFor 属性配置错误
- 事务的传播行为不正确

#### 隔离级别

类似于Mysql

### Spring Boot

#### 自动装配

自动装配可以简单理解为：**通过注解或者一些简单的配置就能在 Spring Boot 的帮助下实现某块功能**

**原理**

大概可以把 `@SpringBootApplication`看作是 `@SpringBootConfiguration`、`@EnableAutoConfiguration`、`@ComponentScan` 注解的集合。根据 SpringBoot 官网，这三个注解的作用分别是：

- `@EnableAutoConfiguration`：启用 SpringBoot 的自动配置机制
- `@SpringBootConfiguration`：允许在上下文中注册额外的 bean 或导入其他配置类
- `@ComponentScan`： 扫描被`@Component` (`@Service`,`@Controller`)注解的 bean，注解默认会扫描启动类所在的包下所有的类 ，可以自定义不扫描某些 bean

**`@EnableAutoConfiguration`:实现自动装配的核心注解**

`EnableAutoConfiguration` 只是一个简单地注解，自动装配核心功能的实现实际是通过 `@Import（AutoConfigurationImportSelector.class）`.`AutoConfigurationImportSelector` 类实现了 `ImportSelector`接口，也就实现了这个接口中的 `selectImports`方法，该方法主要用于**获取所有符合条件类的全限定类名，这些类需要被加载到 IoC 容器中**。

## 设计模式

### 设计原则

#### 单一职责原则

**一个类只承担一个职责**。有时候我们可以将一个复杂的接口拆成两个不同的接口，这两个接口承担着不同的责任，这就是依赖了单一职责原则

#### 接口隔离原则

接口隔离原则（Interface Segregation Principle，ISP）要求程序员尽量将臃肿庞大的接口拆分成更小的和更具体的接口，让接口中只包含客户感兴趣的方法。就是要让接口中的方法尽可能的少而精。

同时注意，根据接口隔离原则拆分接口时，首先必须满足**单一职责原则** ，不能无限拆分。

#### 开闭原则

**对扩展开放，对修改关闭**

#### 里氏替换原则

里氏替换原则通俗来讲就是：

- **子类可以扩展父类的功能，但不能改变父类原有的功能**；
- 只要父类出现的地方子类就可以出现，而且替换为子类不会出现任何错误。

#### 依赖倒置原则

依赖倒置原则在 Java 中的表现是：

- 模块之间的依赖通过抽象产生，实现类之间不能发生依赖关系，只能通过接口或抽象类产生；
- 接口或抽象类不依赖于实现类；
- 实现类依赖接口或抽象类；

#### 迪米特法则

### 单例模式

#### 饿汉式

```java
public class Singleton2 {

    private static final Singleton2 instance = new Singleton2();

    private Singleton2() {
    }

    public static Singleton2 getInstance() {
        return instance;
    }
}

// 创建枚举默认就是线程安全的，所以不需要担心double checked locking，而且还能防止反序列化导致重新创建新的对象。保证只有一个实例（即使使用反射机制也无法多次实例化一个枚举量）
public class Singleton {
    public static void main(String[] args) {
        Single single = Single.SINGLE;
        single.print();
    }

    enum Single {
        SINGLE;

        Single() { // 构造函数默认私有
        }
    }
}
```

**破坏单例的方式以及预防方法**

- **使用反射**：在构造函数中加一层判断，如果已经创建实例，就抛出异常
- **反序列化**：

#### 懒汉式

```java
public class Singleton1 {

    private static Singleton1 instance = null;

    private Singleton1() {
    }

    /**
     * 1、适用于单线程环境（不推荐）
     */
    public static Singleton1 getInstanceA() {
        if (null == instance) { // 相比懒汉式多了一个判断
            instance = new Singleton1();
        }
        return instance;
    }

    /**
     * 2、适用于多线程环境，但效率不高（不推荐）
     */
    public static synchronized Singleton1 getInstanceB() {
        if (instance == null) {
            instance = new Singleton1();
        }
        return instance;
    }

    /**
     * 3、双重检查加锁（推荐）
     */
 		private static Singleton1 instance = null; // 保证有序性
  
    public static Singleton1 getInstanceC() {
        // 先判断实例是否存在，若不存在再对类对象进行加锁处理
        if (instance == null) {
            synchronized (Singleton1.class) {
                if (instance == null) {
                    instance = new Singleton1();
                }
            }
        }
        return instance;  
    }
}

```

### 观察者模式

当对象间存在一对多关系时，则使用观察者模式（Observer Pattern）。比如，当一个对象被修改时，则会自动通知依赖它的对象。观察者模式属于行为型模式。

## 一些零散面试题

### Java 对象创建流程

![image](https://img2020.cnblogs.com/blog/830289/202201/830289-20220116233158867-1686616621.png)

**1.类加载检查**

虚拟机遇到一条new指令时，**首先将去检查这个指令的参数是否能在常量池中定位到一个类的符号引用，并且检查这个符号引用代表的类是否已被加载、解析和初始化过**。如果没有，那必须先执行相应的类加载过程。

new指令对应到语言层面上讲是，new关键词、对象克隆、对象序列化等。

**2.分配内存**

在类加载检查通过后，接下来虚拟机将为新生对象分配内存。对象所需内存的大小在类加载完成后便可完全确定，为对象分配空间的任务等同于把 一块确定大小的内存从Java堆中划分出来。

这个步骤有两个问题：

1.如何划分内存。

2.内存分配同步：在并发情况下， 可能出现正在给对象A分配内存，指针还没来得及修改，对象B又同时使用了原来的指针来分配内存的情况。

**划分内存的方法：**

- “指针碰撞”（Bump the Pointer）(默认用指针碰撞)

如果Java堆中内存是绝对规整的，所有用过的内存都放在一边，空闲的内存放在另一边，中间放着一个指针作为分界点的指示器，那所分配内存就仅仅是把那个指针向空闲空间那边挪动一段与对象大小相等的距离。

- “空闲列表”（Free List）

如果Java堆中的内存并不是规整的，已使用的内存和空 闲的内存相互交错，那就没有办法简单地进行指针碰撞了，虚拟机就必须维护一个列表，记 录上哪些内存块是可用的，在分配的时候从列表中找到一块足够大的空间划分给对象实例， 并更新列表上的记录

使用哪种划分内存的方法取决于垃圾收集器。例如CMS采用标记清除回收算法。

**解决并发问题的方法：**

- CAS（compare and swap）对分配内存空间的动作进行同步处理

虚拟机采用**CAS配上失败重试**的方式保证更新操作的原子性。

- 本地线程分配缓冲（Thread Local Allocation Buffer,TLAB）

把内存分配的动作按照线程划分在不同的空间之中进行，即每个线程在Java堆中预先分配一小块内存。

```diff
-XX:+UseTLAB
-XX:TLABSize
```

**3.初始化零值**

内存分配完成后，虚拟机需要将分配到的内存空间都初始化为零值（不包括对象头）， 如果使用TLAB，这一工作过程也可以提前至TLAB分配时进行。这一步操作保证了对象的实例字段在 Java 代码中可以不赋初始值就直接使用，程序能访问到这些字段的数据类型所对应的零值。

**4.设置对象头**

初始化零值之后，虚拟机要对对象进行必要的设置，例如这个**对象是哪个类的实例、如何才能找到类的元数据信息、对象的哈希码、对象的GC分代年龄**等信息。**这些信息存放在对象的对象头Object Header之中**。

5.执行`<init>`方法

执行`<init>`方法，即对象按照程序员的意愿进行初始化。为**属性赋值和执行构造方法**。

### Java 类加载器，如果自定义一个 String 类，需要怎么做

自定义加载器，继承 `ClassLoader`，重写loadClass()方法打破双亲委派机制

### BigDecimal 原理

BigDecimal的原理很简单，就是将小数扩大N倍，转成整数后再进行计算，同时结合指数，得出没有精度损失的结果

### hash 算法有哪些 ？ Java  hashCode() 方法有哪些实现

MD4、MD5、sha-1、一致性 hash 等

JDK hashcode 的实现方式

- 返回一个伪随机数生成器生成的随机数
- 将对象的内存地址，做移位运算后与一个随机数进行异或得到结果
- 返回固定的1
- 返回一个自增序列的当前值
- 返回当前对象的内存地址

### 对象什么时候会在栈上分配

HotSpot 虚拟机引入了 JIT 优化之后，会对对象进行**逃逸分析**，如果发现某一个对象并没有逃逸到**方法外部**，那么就可能**通过标量替换来实现栈上分配**，而避免堆上分配内存

### ThreadLocalMap 和 HashMap 的对比

- ThreadLocalMap 的 **Key 是指定**的（ThreadLocal）, HashMap 的是任意值
- 使用的**哈希算法**不一样。
- 解决**哈希冲突**的算法不一样。HashMap使用的是链地址法。ThreadLocalMap使用的是开放寻址法

### 指令重排序

**简单来说，就是指在程序中写的代码，并不一定按照写的顺序执行**。为了使处理器内部的运算单元能尽量被充分利用，处理器可能会对输入的代码进行乱序执行优化。Java中的指令重排序有两次

第一次发生在将**字节码编译成机器码**的阶段，第二次发生在**CPU执行**的时候，也会适当对指令进行重排

### 虚引用存在的意义

它存在的唯一目的，就是在回收的时候，能够被感知到，以便进行更深层次的清理

### JVM 参数

最重要和常见的几个参数如下：

■ -Xms20m ：设置jvm初始化堆大小为20m，一般与-Xmx相同避免垃圾回收完成后jvm重新分。

■ -Xmx20m：设置jvm最大可用内存大小为20m。

■ -Xmn10m：设置新生代大小为10m。

■ -Xss128k：设置每个线程的栈大小为128k。

![img](https://pic1.zhimg.com/80/v2-5acf2edfdf919ec7d4bda402e32b779c_1440w.webp)

### JVM调优过程

JVM调优为了降低Minor GC 和 Major GC 的次数，分析是因为动态晋升年龄过小导致老年代频繁被打满，通过调大新生代内存，减少Minor GC 次数，增大了老年代的晋升年龄，进而减少了Major GC 的次数

### OOM 排查和解决

1. **OOM for Heap (java.lang.OutOfMemoryError: Java heap space) **

   **分析**

   此OOM是由于JVM中heap的最大值大于程序运行期间最大可用内存大小，如果程序运行需要占用更多的内存，超出了这个设置值，就会抛出OutOfMemory异常。

   **解决思路**
   将设置heap的最大值调高即可，即-Xmx的值调大。参数样例为：-Xmx2G。

2. **OOM for StackOverflowError (Exception in thread “main” java.lang.StackOverflowError)**

   **分析**

   如果线程请求的栈深度大于虚拟机所允许的最大深度，将抛出StackOverflowError异常。
   如果虚拟机在扩展栈时无法申请到足够的内存空间，则抛出OutOfMemoryError异常。

   **解决思路**
   检查程序是否有深度递归，或者根据-Xss 是指设定每个线程的堆栈大小。

3. **OOM for Perm (java.lang.OutOfMemoryError: PermGen space)**

   **分析**

   PermGen space的全称是Permanent Generation space,是指内存的永久保存区域,这块内存主要是被JVM存放Class和Meta信息的,Class在被Loader时就会被放到PermGen space中。由于JVM在默认的情况下，Perm默认为64M，而很多程序需要大量的Perm区内存，尤其使用到像 Spring 等框架的时候，由于需要使用到动态生成类，而这些类不能被GC自动释放，所以导致OutOfMemoryError: PermGen space异常。

   **解决思路**
   增大JVM的 -XX:MaxPermSize 启动参数，就可以解决这个问题。

4. **OOM for GC (java.lang.OutOfMemoryError: GC overhead limit exceeded)**

   **分析**

   此OOM是由于JVM在GC时，对象过多，导致内存溢出，建议调整GC的策略，在一定比例下开始GC而不要使用默认的策略，或者将新代和老代设置合适的大小。

   **解决思路**
   改变GC策略，在老代80%时就是开始GC，并且将-XX:SurvivorRatio（默认-XX:SurvivorRatio=8，定义了新生代中Eden区域和Survivor区域的比例）和-XX:NewRatio（默认-XX:NewRatio=4，定义了新生代和老年代的比例）设置的更合理。

### 断点续传如何实现

断点续传的原理在于前端/服务端需要**记住已上传的切片**，这样下次上传就可以跳过之前已上传的部分，有两种方案实现记忆的功能

- 前端使用 localStorage 记录已上传的切片 hash.
- 服务端保存已上传的切片 hash，前端每次上传前向服务端获取已上传的切片

### TCP 沾包问题以及处理方法

TCP粘包就是指发送方发送的**若干包数据到达接收方时粘成了一包**。

对于发送方造成的粘包问题，可以通过**关闭Nagle算法**来解决。接收方没有办法来处理粘包现象，只能将问题交给**应用层**来处理。应用层通过**循环处理**来解决。

### http 报文结构

- **起始行**：请求报文里叫请求行，包括请求方法、请求目标（URL）、版本号。响应报文里叫状态行，包括版本号、状态码、原因。
- **头部(header)**：HTTP 头字段非常灵活，不仅可以使用标准里的 Host、Connection、Content-Type、cookie、 等已有头，也可以任意添加自定义头，这就给 HTTP 协议带来了无限的扩展可能
- **实体(body)**

### Content-type 有哪些

1. text开头
   1. text/html： HTML格式
   2. text/plain：纯文本格式
   3. text/xml： XML格式
2. application开头
   application/xhtml+xml：XHTML 格式
   application/xml：XML 数据格式
   application/json：JSON 数据格式
   application/x-www-form-urlencoded：表单发送默认格式
3. Image 开头、媒体文件

### 幂等方法

假如在**不考虑诸如错误或者过期**等问题的情况下，**若干次请求的副作用与单次请求相同或者根本没有副作用**，那么这些请求方法就能够被视作“幂等”的。GET，HEAD，PUT和DELETE方法都有这样的幂等属性。

### 目前最广泛使用的 HTTP 方法

HTTP / 1.1

HTTPs 的 s 代表什么

HTTP on SSL ? Security?

### HTTP Keep-Alive

Keep-Alive 功能**避免了建立或者重新建立连接**。http 1.0中默认是关闭的，需要在http头加入"Connection: Keep-Alive"，才能启用Keep-Alive；http 1.1中默认启用Keep-Alive，如果加入"Connection: close "，才关闭。

启用Keep-Alive模式肯定更高效，性能更高。

### nginx 在哪一层

通常使用的 nginx 负载均衡技术， 在网络分层中处于**应用层**的，nginx 与客户端建立 TCP 连接，然后再根据请求信息以及本地配置信息，将请求灵活的分发到不同的服务上

### Nginx的负载均衡算法

- **轮询（默认）**：每个请求按时间顺序逐一分配到不同的后端服务器，如果后端服务器down掉，能自动剔除
- **weight**：指定轮询几率，weight和访问比率成正比，用于后端服务器性能不均的情况
- **ip_hash**：每个请求按访问 ip 的 hash 结果分配，这样每个访客固定访问一个后端服务器，可以解决session的问题
- **url_hash**：按访问url的hash结果来分配请求，使每个url定向到同一个后端服务器，后端服务器为缓存时比较有效
- **fair**：按后端服务器的响应时间来分配请求，响应时间短的优先分配

### Mysql 查询是否命中索引

使用 explain 指令

### Mysql 优化 sql 语句

通过查询 MySQL 的慢查询日志来发现需要进行优化的 SQL 语句

### Mysql 索引区分度(选择性)

 索引的区分度等于count(distinct 具体的列) / count(*)，表示**字段不重复的比例**。索引的区分度越高则价值就越高。

### 性别是否需要加索引

性别只有三中，区分度很低，不需加索引

### Mysql 中如何存储手机号

因为涉及到固定电话，所以一般用 varchar2，单纯手机号码的话可以用number。

### Mysql 索引优化过程

从无锁引的全表扫描，到建立普通索引的索引扫描，再到联合索引的索引范围扫描，避免了回表的次数

### limit 10000, 10 存在的问题和解决方案

前面的数字越大，耗时越多，因为 mysql 会先查询 10010 条数据，然后丢弃掉前面 10000 行。

解决方案：

- **用 id 优化**：

  ```sql
  select * from user where id>1000000 limit 100.
  ```

  这样的效率非常快,因为主键上是有索引的,但是这样有个缺点,就是`ID必须是连续`的,并且`查询不能有where语句,因为where语句会造成过滤数据.

- **用 覆盖索引 优化**：

### 当查询条件有xx == null 时索引一定会失效吗

带索引字段使用 null 做判断是否走索引与**数据量**有关

### beanFactory 和 ApplicationContext 的区别

 BeanFactory和ApplicationContext是Spring的两大核心接口，都可以当做Spring的容器。其中ApplicationContext是BeanFactory的子接口, 包含 BeanFactory 的所有特性,它的主要功能是支持大型的业务应用的创建。

- BeanFactroy采用的是**延迟加载形式来注入Bean**的，即只有在使用到某个Bean时(调用getBean())，才对该Bean进行加载实例化。ApplicationContext，它是在容器启动时，**一次性创建了所有的Bean**
- BeanFactory和ApplicationContext都支持BeanPostProcessor、BeanFactoryPostProcessor的使用，但两者之间的区别是：BeanFactory需要手动注册，而ApplicationContext则是自动注册
- ApplicationContext 更占用内存空间

### Mybatis ${} 和 #{} 的区别

最的的区别是 #{} 可以防止 sql 注入。 原因是 #{} 先将参数转义插入到 sql 语句中， ${} 直接讲参数加入到 sql 语句中。

### Linux 查询端口被哪个进程进程

netstat -tunpl | grep 端口号

### Linux 查看进程的占用（cpu 等）情况

ps -aux | grep 进程号

### 物理内存只有2g，new一个大小为8g的数组会发生什么

- 在 32 位操作系统，因为进程理论上最大能申请 3 GB 大小的虚拟内存，所以直接申请 8G 内存，会申请失败。

- 在 64位 位操作系统，因为进程理论上最大能申请 128 TB 大小的虚拟内存，即使物理内存只有 4GB，申请 8G 内存也是没问题，因为申请的内存是虚拟内存。如果这块虚拟内存被访问了，要看系统有没有 Swap 分区：

  - 如果没有 Swap 分区，因为物理空间不够，进程会被操作系统杀掉，原因是 OOM（内存溢出）；

  - 如果有 Swap 分区，即使物理内存只有 4GB，程序也能正常使用 8GB 的内存，进程可以正常运行

    > Swap 就是把一块磁盘空间或者本地文件，当成内存来使用，它包含换出和换入两个过程：
    >
    > - **换出（Swap Out）** ，是把进程暂时不用的内存数据存储到磁盘中，并释放这些数据占用的内存；
    > - **换入（Swap In）**，是在进程再次访问这些内存的时候，把它们从磁盘读到内存中来；

### 

